"""
SWRN (Software Release Notes) SQLite FTS5 Indexer
PDF ë¬¸ì„œë¥¼ ì¸ë±ì‹±í•˜ì—¬ ë¹ ë¥¸ PR ê²€ìƒ‰ ì§€ì›

ì‚¬ìš©ë²•:
    python swrn_indexer.py --build      # ì¸ë±ìŠ¤ êµ¬ì¶• (ìµœì´ˆ 1íšŒ)
    python swrn_indexer.py --search "PR-195121"  # PR ê²€ìƒ‰
    python swrn_indexer.py --update     # ìƒˆ íŒŒì¼ë§Œ ì¶”ê°€ ì¸ë±ì‹±
"""

import os
import re
import sqlite3
import json
import time
from pathlib import Path
from typing import Optional, List, Dict, Tuple
from datetime import datetime

# PyMuPDF
try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
except ImportError:
    PYMUPDF_AVAILABLE = False
    print("âš ï¸ PyMuPDF not installed. Run: pip install PyMuPDF")

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„
try:
    from similar_pr_engine import HybridPRSearchEngine, get_hybrid_search_engine
    HYBRID_SEARCH_AVAILABLE = True
except ImportError:
    HYBRID_SEARCH_AVAILABLE = False
    HybridPRSearchEngine = None


def parse_sw_version(version_str: str) -> Tuple[int, int, int, int, int]:
    """
    SW ë²„ì „ ë¬¸ìì—´ì„ ì •ë ¬ ê°€ëŠ¥í•œ íŠœí”Œë¡œ ë³€í™˜
    ì˜ˆ: "1.8.4-SP28-HF11-Release" -> (1, 8, 4, 28, 11)
        "1.8.4-SP28-Release" -> (1, 8, 4, 28, 0)
        "1.8.4-SP27-B2-Release" -> (1, 8, 4, 27, -2)  # B ë¹Œë“œëŠ” HFë³´ë‹¤ ë‚®ìŒ
    
    ì •ë ¬ ìš°ì„ ìˆœìœ„: ë†’ì€ ë²„ì „ì´ ë¨¼ì € (ë‚´ë¦¼ì°¨ìˆœ)
    """
    if not version_str:
        return (0, 0, 0, 0, 0)
    
    # ë²„ì „ ë¬¸ìì—´ ì •ê·œí™”
    v = version_str.upper()
    
    # ë©”ì¸ ë²„ì „ ì¶”ì¶œ (ì˜ˆ: 1.8.4)
    main_match = re.search(r'(\d+)\.(\d+)\.(\d+)', v)
    major, minor, patch = (0, 0, 0)
    if main_match:
        major = int(main_match.group(1))
        minor = int(main_match.group(2))
        patch = int(main_match.group(3))
    
    # SP ë²ˆí˜¸ ì¶”ì¶œ
    sp_match = re.search(r'SP(\d+)', v)
    sp_num = int(sp_match.group(1)) if sp_match else 0
    
    # HF ë²ˆí˜¸ ì¶”ì¶œ (Hotfixê°€ ìˆìœ¼ë©´ Releaseë³´ë‹¤ ë†’ìŒ)
    hf_match = re.search(r'HF(\d+)', v)
    if hf_match:
        hf_num = int(hf_match.group(1))  # HF11 = 11
    else:
        # B ë¹Œë“œ í™•ì¸ (HFë³´ë‹¤ ë‚®ìŒ)
        b_match = re.search(r'-B(\d+)-', v)
        if b_match:
            hf_num = -int(b_match.group(1))  # B2 = -2 (HF0ë³´ë‹¤ ë‚®ìŒ)
        else:
            # HF ì—†ìŒ = ê¸°ë³¸ Release = 0
            hf_num = 0
    
    return (major, minor, patch, sp_num, hf_num)


class SWRNIndexer:
    """SWRN PDF ë¬¸ì„œ ì¸ë±ì„œ - SQLite FTS5 ê¸°ë°˜"""
    
    def __init__(self, swrn_folder: str = None, db_path: str = None):
        self.base_dir = Path(__file__).parent
        self.swrn_folder = Path(swrn_folder) if swrn_folder else self.base_dir / "data" / "SWRN"
        self.db_path = Path(db_path) if db_path else self.base_dir / "data" / "swrn_index.db"
        
        # DB ë””ë ‰í† ë¦¬ ìƒì„±
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (ì§€ì—° ì´ˆê¸°í™”)
        self._hybrid_engine = None
        
    def _create_tables(self, conn: sqlite3.Connection):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±"""
        cursor = conn.cursor()
        
        # íŒŒì¼ ì •ë³´ í…Œì´ë¸”
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS pdf_files (
                id INTEGER PRIMARY KEY,
                filename TEXT UNIQUE,
                filepath TEXT,
                sw_version TEXT,
                file_size INTEGER,
                page_count INTEGER,
                indexed_at TEXT
            )
        """)
        
        # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ í…Œì´ë¸” (FTS5 ê°€ìƒ í…Œì´ë¸”)
        cursor.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS page_content USING fts5(
                file_id,
                page_num,
                content,
                tokenize='unicode61'
            )
        """)
        
        # PR ì¸ë±ìŠ¤ í…Œì´ë¸” (ë¹ ë¥¸ PR ê²€ìƒ‰ìš©)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS pr_index (
                pr_number TEXT,
                file_id INTEGER,
                page_num INTEGER,
                context TEXT,
                pr_type TEXT DEFAULT 'unknown',
                PRIMARY KEY (pr_number, file_id, page_num),
                FOREIGN KEY (file_id) REFERENCES pdf_files(id)
            )
        """)
        
        # pr_type ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€ (ê¸°ì¡´ DB ë§ˆì´ê·¸ë ˆì´ì…˜)
        try:
            cursor.execute("ALTER TABLE pr_index ADD COLUMN pr_type TEXT DEFAULT 'unknown'")
            conn.commit()
        except sqlite3.OperationalError:
            pass  # ì´ë¯¸ ì»¬ëŸ¼ì´ ì¡´ì¬í•¨
        
        # PR ë²ˆí˜¸ ì¸ë±ìŠ¤
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_pr_number ON pr_index(pr_number)
        """)
        
        conn.commit()
    
    def _extract_version_from_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ SW ë²„ì „ ì¶”ì¶œ"""
        # Version_1.8.4-SP34-Release_ReleaseNotes.pdf -> 1.8.4-SP34-Release
        match = re.search(r'Version[_-]?([\d.]+[-\w]*)', filename, re.IGNORECASE)
        if match:
            return match.group(1)
        return "Unknown"
    
    def _detect_pr_type(self, text: str, pr_position: int) -> str:
        """PRì´ New Featureì¸ì§€ Issue Fixì¸ì§€ ê°ì§€
        
        ë¬¸ì„œ êµ¬ì¡°:
        - 'New and Enhanced Features' ì„¹ì…˜ â†’ 'new_feature'
        - 'Problem Report and Escalations' ì„¹ì…˜ â†’ 'issue_fix'
        
        Args:
            text: í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸
            pr_position: PR ë²ˆí˜¸ê°€ ë‚˜ì˜¨ ìœ„ì¹˜
            
        Returns:
            'new_feature' ë˜ëŠ” 'issue_fix' ë˜ëŠ” 'unknown'
        """
        # PR ìœ„ì¹˜ ì´ì „ì˜ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ í—¤ë” ì°¾ê¸°
        text_before_pr = text[:pr_position].lower()
        
        # ê°€ì¥ ë§ˆì§€ë§‰ì— ë‚˜ì˜¨ ì„¹ì…˜ í—¤ë” ì°¾ê¸°
        new_feature_pos = -1
        issue_fix_pos = -1
        
        # New and Enhanced Features ì„¹ì…˜ íŒ¨í„´
        new_feature_patterns = [
            'new and enhanced features',
            'new features',
            'enhanced features',
            'ald features',  # ALD Features from 1.8.4-SP35
            'features from'
        ]
        
        # Problem Report and Escalations ì„¹ì…˜ íŒ¨í„´  
        issue_fix_patterns = [
            'problem report and escalations',
            'problem reports',
            'escalations',
            'defect fixes',
            'bug fixes'
        ]
        
        for pattern in new_feature_patterns:
            pos = text_before_pr.rfind(pattern)
            if pos > new_feature_pos:
                new_feature_pos = pos
                
        for pattern in issue_fix_patterns:
            pos = text_before_pr.rfind(pattern)
            if pos > issue_fix_pos:
                issue_fix_pos = pos
        
        # ë” ìµœê·¼ì— ë‚˜ì˜¨ ì„¹ì…˜ í—¤ë”ë¡œ íŒë‹¨
        if new_feature_pos > issue_fix_pos:
            return 'new_feature'
        elif issue_fix_pos > new_feature_pos:
            return 'issue_fix'
        else:
            # í—¤ë”ë¥¼ ëª» ì°¾ì€ ê²½ìš°, í‚¤ì›Œë“œë¡œ ì¶”ë¡ 
            text_around = text[max(0, pr_position-500):pr_position+500].lower()
            if 'description' in text_around and 'benefit' in text_around:
                return 'new_feature'
            elif 'issue description' in text_around or 'root cause' in text_around or 'solution' in text_around:
                return 'issue_fix'
            return 'unknown'
    
    def _extract_pr_numbers(self, text: str) -> List[Tuple[str, str, str]]:
        """í…ìŠ¤íŠ¸ì—ì„œ PR ë²ˆí˜¸, ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸, PR ìœ í˜• ì¶”ì¶œ
        
        PDF ë¬¸ì„œì—ì„œ ì‹¤ì œ PR í•­ëª©ë§Œ ì¶”ì¶œ (History, Description ë“±ì— ì–¸ê¸‰ëœ ê´€ë ¨ PR ì œì™¸)
        
        ìœ íš¨í•œ PR íŒ¨í„´:
        - ì„¹ì…˜ ë²ˆí˜¸ íŒ¨í„´: "5.1.1.1.1. PR-XXXXXX :" ë˜ëŠ” "6.2.1.1.1. PR-XXXXXX :"
        - ì œëª© íŒ¨í„´: ì¤„ ì‹œì‘ì— "PR-XXXXXX :" ë˜ëŠ” "PR-XXXXXX:" í˜•íƒœ
        
        Returns:
            List of (pr_number, context, pr_type) tuples
        """
        results = []
        seen_prs = set()  # ì¤‘ë³µ ë°©ì§€
        
        # íŒ¨í„´ 1: ì„¹ì…˜ ë²ˆí˜¸ê°€ ìˆëŠ” PR ì œëª© (ê°€ì¥ ì •í™•)
        # ì˜ˆ: "5.1.1.1.1. PR-197591 : High Pass Filtered SVID..."
        # ì˜ˆ: "6.2.1.1.1. PR-196198 : No Warning/Alarm when..."
        section_pr_pattern = r'(\d+\.\d+\.\d+\.\d+\.\d+\.)\s*PR[-\s]?(\d{6})\s*[:\-]'
        
        for match in re.finditer(section_pr_pattern, text):
            pr_num = f"PR-{match.group(2)}"
            if pr_num in seen_prs:
                continue
            seen_prs.add(pr_num)
            
            # PR ì£¼ë³€ 300ì ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì œëª© í¬í•¨)
            start = match.start()
            end = min(len(text), match.end() + 300)
            context = text[start:end].replace('\n', ' ').strip()
            
            # PR ìœ í˜• ê°ì§€ (ì„¹ì…˜ ë²ˆí˜¸ë¡œ íŒë‹¨)
            section_num = match.group(1)
            if section_num.startswith('5.'):
                pr_type = 'feature'  # Section 5: New and Enhanced Features
            elif section_num.startswith('6.'):
                pr_type = 'bug_fix'  # Section 6: Problem Report and Escalations
            else:
                pr_type = self._detect_pr_type(text, match.start())
            
            results.append((pr_num, context, pr_type))
        
        # íŒ¨í„´ 2: ì„¹ì…˜ ë²ˆí˜¸ ì—†ì´ ì¤„ ì‹œì‘ì— PR ì œëª© (ë°±ì—… íŒ¨í„´)
        # ì˜ˆ: "PR-197591 : High Pass Filtered..."
        # ë‹¨, History, Description ë“±ì—ì„œ ì–¸ê¸‰ëœ PRì€ ì œì™¸
        line_pr_pattern = r'(?:^|\n)\s*PR[-\s]?(\d{6})\s*[:\-]\s*([^\n]{10,})'
        
        for match in re.finditer(line_pr_pattern, text):
            pr_num = f"PR-{match.group(1)}"
            if pr_num in seen_prs:
                continue
            
            # ì£¼ë³€ í…ìŠ¤íŠ¸ í™•ì¸ - History, Description ë“±ì—ì„œ ì–¸ê¸‰ëœ ê²ƒ ì œì™¸
            start_context = max(0, match.start() - 200)
            before_text = text[start_context:match.start()].lower()
            
            # ì œì™¸ í‚¤ì›Œë“œ: ì´ PRì´ ë‹¤ë¥¸ ì„¹ì…˜ì—ì„œ ì°¸ì¡°ë˜ëŠ” ê²½ìš°
            exclude_keywords = ['history', 'description', 'see pr', 'related pr', 
                               'refer to', 'same as', 'duplicate', 'fixed in',
                               'introduced in', 'caused by', 'root cause']
            
            if any(kw in before_text[-100:] for kw in exclude_keywords):
                continue
            
            seen_prs.add(pr_num)
            
            # PR ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
            end = min(len(text), match.end() + 200)
            context = text[match.start():end].replace('\n', ' ').strip()
            
            # PR ìœ í˜• ê°ì§€
            pr_type = self._detect_pr_type(text, match.start())
            
            results.append((pr_num, context, pr_type))
        
        return results
    
    def build_index(self, force_rebuild: bool = False) -> Dict:
        """ì „ì²´ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        if not PYMUPDF_AVAILABLE:
            return {"error": "PyMuPDF not installed"}
        
        if not self.swrn_folder.exists():
            return {"error": f"SWRN folder not found: {self.swrn_folder}"}
        
        # ê¸°ì¡´ DB ì‚­ì œ (ê°•ì œ ì¬êµ¬ì¶• ì‹œ)
        if force_rebuild and self.db_path.exists():
            os.remove(self.db_path)
            print(f"ğŸ—‘ï¸ Removed existing index: {self.db_path}")
        
        conn = sqlite3.Connection(str(self.db_path))
        self._create_tables(conn)
        cursor = conn.cursor()
        
        # PDF íŒŒì¼ ëª©ë¡
        pdf_files = list(self.swrn_folder.glob("*.pdf"))
        total_files = len(pdf_files)
        
        if total_files == 0:
            return {"error": "No PDF files found"}
        
        print(f"\n{'='*60}")
        print(f"ğŸ“š SWRN Indexer - Building Index")
        print(f"{'='*60}")
        print(f"ğŸ“ Folder: {self.swrn_folder}")
        print(f"ğŸ“„ Files: {total_files}")
        print(f"ğŸ’¾ Database: {self.db_path}")
        print(f"{'='*60}\n")
        
        stats = {
            "total_files": total_files,
            "processed_files": 0,
            "total_pages": 0,
            "total_prs": 0,
            "errors": [],
            "start_time": time.time()
        }
        
        for idx, pdf_path in enumerate(pdf_files, 1):
            filename = pdf_path.name
            
            # ì´ë¯¸ ì¸ë±ì‹±ëœ íŒŒì¼ ìŠ¤í‚µ (ì—…ë°ì´íŠ¸ ëª¨ë“œ)
            if not force_rebuild:
                cursor.execute("SELECT id FROM pdf_files WHERE filename = ?", (filename,))
                if cursor.fetchone():
                    print(f"â­ï¸ [{idx}/{total_files}] Skipping (already indexed): {filename}")
                    continue
            
            print(f"ğŸ“– [{idx}/{total_files}] Processing: {filename}")
            
            try:
                doc = fitz.open(str(pdf_path))
                page_count = len(doc)
                sw_version = self._extract_version_from_filename(filename)
                file_size = pdf_path.stat().st_size
                
                # íŒŒì¼ ì •ë³´ ì €ì¥
                cursor.execute("""
                    INSERT OR REPLACE INTO pdf_files 
                    (filename, filepath, sw_version, file_size, page_count, indexed_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (filename, str(pdf_path), sw_version, file_size, page_count, 
                      datetime.now().isoformat()))
                
                file_id = cursor.lastrowid
                
                # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì¸ë±ì‹±
                file_pr_count = 0
                for page_num in range(page_count):
                    page = doc[page_num]
                    text = page.get_text()
                    
                    if not text.strip():
                        continue
                    
                    # FTS5ì— í˜ì´ì§€ ë‚´ìš© ì €ì¥
                    cursor.execute("""
                        INSERT INTO page_content (file_id, page_num, content)
                        VALUES (?, ?, ?)
                    """, (str(file_id), str(page_num + 1), text))
                    
                    # PR ë²ˆí˜¸ ì¶”ì¶œ ë° ì¸ë±ì‹± (pr_type í¬í•¨)
                    pr_entries = self._extract_pr_numbers(text)
                    for pr_num, context, pr_type in pr_entries:
                        cursor.execute("""
                            INSERT OR REPLACE INTO pr_index (pr_number, file_id, page_num, context, pr_type)
                            VALUES (?, ?, ?, ?, ?)
                        """, (pr_num, file_id, page_num + 1, context, pr_type))
                        file_pr_count += 1
                    
                    # ì§„í–‰ë¥  í‘œì‹œ (50í˜ì´ì§€ë§ˆë‹¤)
                    if (page_num + 1) % 50 == 0:
                        print(f"   ğŸ“„ Page {page_num + 1}/{page_count}...")
                
                doc.close()
                conn.commit()
                
                stats["processed_files"] += 1
                stats["total_pages"] += page_count
                stats["total_prs"] += file_pr_count
                
                print(f"   âœ… {page_count} pages, {file_pr_count} PRs indexed")
                
            except Exception as e:
                error_msg = f"{filename}: {str(e)}"
                stats["errors"].append(error_msg)
                print(f"   âŒ Error: {e}")
                continue
        
        conn.close()
        
        # ì™„ë£Œ í†µê³„
        elapsed = time.time() - stats["start_time"]
        stats["elapsed_seconds"] = elapsed
        
        print(f"\n{'='*60}")
        print(f"âœ… Indexing Complete!")
        print(f"{'='*60}")
        print(f"ğŸ“„ Files processed: {stats['processed_files']}/{total_files}")
        print(f"ğŸ“‘ Total pages: {stats['total_pages']:,}")
        print(f"ğŸ”¢ Total PRs indexed: {stats['total_prs']:,}")
        print(f"â±ï¸ Time elapsed: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)")
        print(f"ğŸ’¾ Database size: {self.db_path.stat().st_size / 1024 / 1024:.1f} MB")
        
        if stats["errors"]:
            print(f"\nâš ï¸ Errors ({len(stats['errors'])}):")
            for err in stats["errors"][:5]:
                print(f"   - {err}")
        
        return stats
    
    def get_prs_between_versions(self, version_from: str, version_to: str, include_details: bool = True) -> Dict:
        """
        ë‘ ë²„ì „ ì‚¬ì´ì— ì¶”ê°€ëœ PRë“¤ì„ ê²€ìƒ‰ (Delta Summary ìŠ¤íƒ€ì¼)
        
        Args:
            version_from: ì‹œì‘ ë²„ì „ (ì˜ˆ: "1.8.4-SP33-HF9e")
            version_to: ì¢…ë£Œ ë²„ì „ (ì˜ˆ: "1.8.4-SP33-HF16")
            include_details: PR ìƒì„¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
        
        Returns:
            Dict with:
                - prs: ì¶”ê°€ëœ PR ëª©ë¡ (ìƒì„¸ ì •ë³´ í¬í•¨)
                - versions_included: í¬í•¨ëœ ë²„ì „ë“¤
                - from_version: ì‹œì‘ ë²„ì „
                - to_version: ì¢…ë£Œ ë²„ì „
                - summary: Delta Summary í†µê³„
        """
        if not self.db_path.exists():
            return {"error": "SWRN index not found", "prs": []}
        
        # ë²„ì „ íŠœí”Œ ë³€í™˜
        from_tuple = parse_sw_version(version_from)
        to_tuple = parse_sw_version(version_to)
        
        # fromì´ toë³´ë‹¤ í¬ë©´ ìŠ¤ì™‘
        if from_tuple > to_tuple:
            from_tuple, to_tuple = to_tuple, from_tuple
            version_from, version_to = version_to, version_from
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        # ëª¨ë“  ë²„ì „ê³¼ PR ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        cursor.execute("""
            SELECT DISTINCT f.sw_version, p.pr_number, p.context, p.pr_type
            FROM pr_index p
            JOIN pdf_files f ON p.file_id = f.id
            WHERE p.pr_number IS NOT NULL AND p.pr_number != ''
            ORDER BY f.sw_version
        """)
        
        rows = cursor.fetchall()
        conn.close()
        
        # ë²„ì „ë³„ PR ë¶„ë¥˜
        version_prs = {}  # version -> set of PRs
        all_versions = set()
        
        for row in rows:
            sw_version = row[0]
            pr_number = row[1]
            context = row[2] if len(row) > 2 else ""
            pr_type = row[3] if len(row) > 3 else "unknown"
            
            ver_tuple = parse_sw_version(sw_version)
            all_versions.add((ver_tuple, sw_version))
            
            # from ì´í›„ ~ to ì´í•˜ì¸ ë²„ì „ë§Œ í¬í•¨
            if from_tuple < ver_tuple <= to_tuple:
                if sw_version not in version_prs:
                    version_prs[sw_version] = {}
                if pr_number not in version_prs[sw_version]:
                    version_prs[sw_version][pr_number] = {
                        "pr_number": pr_number,
                        "context": context,
                        "pr_type": pr_type,
                        "sw_version": sw_version
                    }
        
        # ì •ë ¬ëœ ë²„ì „ ëª©ë¡ (from ì´í›„ ~ to ì´í•˜)
        sorted_versions = sorted(
            [(ver_tuple, sw_version) for ver_tuple, sw_version in all_versions 
             if from_tuple < ver_tuple <= to_tuple],
            key=lambda x: x[0]
        )
        
        # from ë²„ì „ì˜ PR ëª©ë¡ (ì´ë¯¸ ì¡´ì¬í•˜ëŠ” PR)
        cursor = sqlite3.connect(str(self.db_path)).cursor()
        cursor.execute("""
            SELECT DISTINCT p.pr_number
            FROM pr_index p
            JOIN pdf_files f ON p.file_id = f.id
            WHERE p.pr_number IS NOT NULL AND p.pr_number != ''
        """)
        
        # from ë²„ì „ ì´í•˜ì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  PR
        base_prs = set()
        rows = cursor.fetchall()
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        for ver_tuple, sw_version in all_versions:
            if ver_tuple <= from_tuple:
                cursor.execute("""
                    SELECT DISTINCT p.pr_number
                    FROM pr_index p
                    JOIN pdf_files f ON p.file_id = f.id
                    WHERE f.sw_version = ?
                """, (sw_version,))
                for row in cursor.fetchall():
                    base_prs.add(row[0])
        
        conn.close()
        
        # í•´ë‹¹ ë²„ì „ ë²”ìœ„ì˜ ëª¨ë“  PR ìˆ˜ì§‘ (ì´ì „ ë²„ì „ì— ìˆë˜ PRë„ í¬í•¨)
        all_prs = []
        versions_included = []
        seen_prs = set()  # ì¤‘ë³µ ë°©ì§€ìš©
        
        for ver_tuple, sw_version in sorted_versions:
            versions_included.append(sw_version)
            if sw_version in version_prs:
                for pr_number, pr_info in version_prs[sw_version].items():
                    if pr_number not in seen_prs:
                        # ì´ì „ ë²„ì „ì— ìˆì—ˆëŠ”ì§€ í‘œì‹œ
                        pr_info["is_new"] = pr_number not in base_prs
                        all_prs.append(pr_info)
                        seen_prs.add(pr_number)
                        # base_prsì— ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ ë²„ì „ì—ì„œ ì¤‘ë³µ ì²´í¬
                        base_prs.add(pr_number)
        
        # PR ìƒì„¸ ì •ë³´ ì¶”ê°€ (include_details=Trueì¸ ê²½ìš°)
        if include_details and all_prs:
            detailed_prs = []
            for pr_info in all_prs:
                pr_number = pr_info["pr_number"]
                try:
                    detail_result = self.get_pr_detail(pr_number)
                    if detail_result and "detail" in detail_result:
                        detail = detail_result["detail"]
                        pr_info["component"] = detail.get("component", "")
                        pr_info["module"] = detail.get("module", "")
                        pr_info["module_type"] = detail.get("module_type", "")
                        pr_info["affected_function"] = detail.get("affected_function", "")
                        pr_info["title"] = detail.get("title", "")
                        pr_info["benefits"] = detail.get("benefits", "")
                        pr_info["history"] = detail.get("history", "")
                except Exception as e:
                    pass  # ìƒì„¸ ì •ë³´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì •ë³´ë§Œ ì‚¬ìš©
                detailed_prs.append(pr_info)
            all_prs = detailed_prs
        
        # Delta Summary í†µê³„ ìƒì„±
        summary = self._generate_delta_summary(all_prs)
        
        # ìƒˆë¡œ ì¶”ê°€ëœ PR ìˆ˜ ê³„ì‚°
        new_pr_count = sum(1 for pr in all_prs if pr.get("is_new", False))
        
        return {
            "from_version": version_from,
            "to_version": version_to,
            "versions_included": versions_included,
            "total_prs": len(all_prs),
            "total_new_prs": new_pr_count,
            "prs": all_prs,
            "summary": summary
        }

    def _generate_delta_summary(self, prs: List[Dict]) -> Dict:
        """
        Delta Summary í†µê³„ ìƒì„± (PR íƒ€ì…ë³„, ì»´í¬ë„ŒíŠ¸ë³„ ë¶„ë¥˜)
        """
        summary = {
            "by_type": {
                "features": [],  # new features
                "bugs": []       # bug fixes
            },
            "by_component": {},
            "by_module": {},
            "by_version": {}
        }
        
        for pr in prs:
            pr_number = pr.get("pr_number", "")
            pr_type = pr.get("pr_type", "unknown").lower()
            component = pr.get("component", "") or "Unknown"
            module = pr.get("module", "") or "Unknown"
            sw_version = pr.get("sw_version", "") or "Unknown"
            
            # Typeë³„ ë¶„ë¥˜ (new/feature -> features, fixed -> bugs)
            if pr_type in ("new", "feature"):
                summary["by_type"]["features"].append(pr_number)
            else:
                summary["by_type"]["bugs"].append(pr_number)
            
            # Componentë³„ ë¶„ë¥˜
            if component not in summary["by_component"]:
                summary["by_component"][component] = []
            summary["by_component"][component].append(pr_number)
            
            # Moduleë³„ ë¶„ë¥˜
            if module not in summary["by_module"]:
                summary["by_module"][module] = []
            summary["by_module"][module].append(pr_number)
            
            # Versionë³„ ë¶„ë¥˜
            if sw_version not in summary["by_version"]:
                summary["by_version"][sw_version] = []
            summary["by_version"][sw_version].append(pr_number)
        
        return summary

    def search_pr(self, pr_number: str) -> List[Dict]:
        """PR ë²ˆí˜¸ë¡œ ê²€ìƒ‰ - ìµœì‹  SW ë²„ì „ ìš°ì„  (HF > Release > B ë¹Œë“œ)"""
        if not self.db_path.exists():
            return []
        
        # PR ë²ˆí˜¸ ì •ê·œí™”
        pr_num = pr_number.upper().strip()
        if not pr_num.startswith("PR-"):
            if re.match(r'^\d{6}$', pr_num):
                pr_num = f"PR-{pr_num}"
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        # ëª¨ë“  ë²„ì „ì—ì„œ PR ê²€ìƒ‰
        cursor.execute("""
            SELECT 
                p.pr_number,
                f.filename,
                f.sw_version,
                p.page_num,
                p.context,
                p.pr_type
            FROM pr_index p
            JOIN pdf_files f ON p.file_id = f.id
            WHERE p.pr_number = ?
        """, (pr_num,))
        
        raw_results = []
        seen_files = {}  # filename -> best result for that file
        
        for row in cursor.fetchall():
            filename = row[1]
            sw_version = row[2]
            page_num = row[3]
            
            # ê°™ì€ íŒŒì¼ì—ì„œëŠ” ê°€ì¥ í° í˜ì´ì§€ ë²ˆí˜¸ë§Œ ì‚¬ìš© (ìƒì„¸ ì •ë³´ í˜ì´ì§€)
            if filename in seen_files:
                if page_num > seen_files[filename]['page']:
                    seen_files[filename]['page'] = page_num
                    seen_files[filename]['context'] = row[4]
                continue
            
            # pr_type ì²˜ë¦¬
            pr_type = row[5] if len(row) > 5 else 'unknown'
            
            seen_files[filename] = {
                "pr_number": row[0],
                "filename": filename,
                "sw_version": sw_version,
                "page": page_num,
                "context": row[4],
                "pr_type": pr_type,
                "_version_tuple": parse_sw_version(sw_version)
            }
        
        conn.close()
        
        # ë²„ì „ íŠœí”Œ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹  ë²„ì „ ë¨¼ì €)
        results = list(seen_files.values())
        results.sort(key=lambda x: x.get("_version_tuple", (0,0,0,0,0)), reverse=True)
        
        # ì •ë ¬ìš© íŠœí”Œ ì œê±°
        for r in results:
            r.pop("_version_tuple", None)
        
        return results
    
    def search_text(self, query: str, limit: int = 20) -> List[Dict]:
        """ì „ë¬¸ ê²€ìƒ‰ (FTS5)"""
        if not self.db_path.exists():
            return []
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        # FTS5 ê²€ìƒ‰
        cursor.execute("""
            SELECT 
                f.filename,
                f.sw_version,
                pc.page_num,
                snippet(page_content, 2, '<b>', '</b>', '...', 30) as snippet
            FROM page_content pc
            JOIN pdf_files f ON CAST(pc.file_id AS INTEGER) = f.id
            WHERE page_content MATCH ?
            ORDER BY rank
            LIMIT ?
        """, (query, limit))
        
        results = []
        for row in cursor.fetchall():
            results.append({
                "filename": row[0],
                "sw_version": row[1],
                "page": int(row[2]),
                "snippet": row[3]
            })
        
        conn.close()
        return results
    
    def get_pr_detail(self, pr_number: str) -> Optional[Dict]:
        """PR ìƒì„¸ ì •ë³´ - ì—¬ëŸ¬ í˜ì´ì§€ì— ê±¸ì¹œ PRë„ ì™„ì „íˆ ì¶”ì¶œ"""
        results = self.search_pr(pr_number)
        
        if not results:
            return None
        
        # ê°€ì¥ ìµœì‹  ë²„ì „ì˜ ê²°ê³¼ ì‚¬ìš©
        result = results[0]
        
        # í•´ë‹¹ PDFì˜ í•´ë‹¹ í˜ì´ì§€ì—ì„œ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
        pdf_path = self.swrn_folder / result["filename"]
        
        if not pdf_path.exists():
            return result
        
        try:
            doc = fitz.open(str(pdf_path))
            db_page = result["page"] - 1  # 0-indexed, DBì— ì €ì¥ëœ í˜ì´ì§€ (ëª©ì°¨ì¼ ìˆ˜ ìˆìŒ)
            total_pages = len(doc)
            
            # PR ë²ˆí˜¸ ì •ê·œí™”
            pr_num = pr_number.replace("PR-", "")
            next_pr_pattern = re.compile(r'\d+\.\d+\.\d+\.\d+\.\d+\.\s*PR[-\s]?\d{6}')
            
            # DB í˜ì´ì§€ê°€ ëª©ì°¨(TOC)ì¸ì§€ í™•ì¸í•˜ê³ , ì‹¤ì œ ìƒì„¸ í˜ì´ì§€ ì°¾ê¸°
            # ëª©ì°¨ í˜ì´ì§€ íŠ¹ì§•: "Component:" ë˜ëŠ” "Module:" ì—†ì´ PR ë²ˆí˜¸ë§Œ ìˆìŒ
            db_page_text = doc[db_page].get_text() if db_page < total_pages else ""
            
            # PR ìƒì„¸ ë‚´ìš©ì´ ìˆëŠ” í˜ì´ì§€ ì°¾ê¸° (Component: ë˜ëŠ” Benefits ë“±ì´ ìˆëŠ” í˜ì´ì§€)
            start_page = db_page
            pr_pattern = re.compile(rf'PR[-\s]?{pr_num}', re.IGNORECASE)
            detail_indicators = ['Component:', 'Module:', 'Benefits', 'Description', 'History', 'CV(Configurable Variable)']
            
            # DB í˜ì´ì§€ì— PR ë²ˆí˜¸ê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸
            has_pr_in_db_page = pr_pattern.search(db_page_text) is not None
            
            # DB í˜ì´ì§€ì— ìƒì„¸ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_detail = any(ind in db_page_text for ind in detail_indicators)
            
            # â˜… ìˆ˜ì •: DB í˜ì´ì§€ì— PR ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ê·¸ í˜ì´ì§€ ì‚¬ìš© (Release Notes Summary í˜•ì‹ ì§€ì›)
            if not has_pr_in_db_page and not has_detail:
                # ëª©ì°¨ í˜ì´ì§€ì¼ ê°€ëŠ¥ì„± â†’ ì „ì²´ PDFì—ì„œ ìƒì„¸ í˜ì´ì§€ ì°¾ê¸°
                for page_idx in range(total_pages):
                    page_text = doc[page_idx].get_text()
                    # PR ë²ˆí˜¸ê°€ ìˆê³  ìƒì„¸ ì •ë³´ ì§€í‘œê°€ ìˆëŠ” í˜ì´ì§€
                    if pr_pattern.search(page_text) and any(ind in page_text for ind in detail_indicators):
                        # í•´ë‹¹ PRì˜ ìƒì„¸ ë‚´ìš©ì¸ì§€ ì¶”ê°€ í™•ì¸
                        # PR ë²ˆí˜¸ ê·¼ì²˜ì— Component: ë“±ì´ ìˆì–´ì•¼ í•¨
                        pr_match = pr_pattern.search(page_text)
                        if pr_match:
                            after_pr = page_text[pr_match.end():pr_match.end()+500]
                            if any(ind in after_pr for ind in detail_indicators[:3]):  # Component:, Module:, Benefits
                                start_page = page_idx
                                break
            
            # ì‹œì‘ í˜ì´ì§€ë¶€í„° ìµœëŒ€ 5í˜ì´ì§€ê¹Œì§€ ì½ê¸° (ëŒ€ë¶€ë¶„ PRì€ 1-3í˜ì´ì§€)
            full_text = ""
            pages_read = 0
            max_pages = 5
            
            for page_idx in range(start_page, min(start_page + max_pages, total_pages)):
                page = doc[page_idx]
                page_text = page.get_text()
                
                if page_idx == start_page:
                    # ì²« í˜ì´ì§€ëŠ” ì „ì²´ ì¶”ê°€
                    full_text += page_text
                    pages_read += 1
                else:
                    # ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ìƒˆë¡œìš´ PRì´ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
                    # ìƒˆ PR íŒ¨í„´ì´ í˜ì´ì§€ ìƒë‹¨ì— ìˆìœ¼ë©´ ì¤‘ë‹¨
                    first_500_chars = page_text[:500]
                    if next_pr_pattern.search(first_500_chars):
                        # ìƒˆ PRì´ ì‹œì‘í•˜ê¸° ì „ê¹Œì§€ë§Œ í¬í•¨
                        match = next_pr_pattern.search(page_text)
                        if match:
                            full_text += page_text[:match.start()]
                        break
                    else:
                        # í˜„ì¬ PRì´ ê³„ì†ë˜ë©´ í˜ì´ì§€ ì „ì²´ ì¶”ê°€
                        full_text += "\n" + page_text
                        pages_read += 1
                        
                        # í˜ì´ì§€ ë‚´ì—ì„œ ìƒˆ PR íŒ¨í„´ì´ ìˆìœ¼ë©´ ê±°ê¸°ê¹Œì§€ë§Œ
                        match = next_pr_pattern.search(page_text)
                        if match:
                            # ë‹¤ìŒ PRì´ ì‹œì‘ë˜ë©´ ì¤‘ë‹¨
                            break
            
            doc.close()
            
            # PR ìƒì„¸ ì •ë³´ íŒŒì‹±
            detail = self._parse_pr_detail(pr_number, full_text)
            detail["_pages_read"] = pages_read  # ë””ë²„ê¹…ìš©
            detail["_start_page"] = start_page  # ë””ë²„ê¹…ìš©
            detail["_db_page"] = db_page  # ë””ë²„ê¹…ìš©
            detail["_full_text_len"] = len(full_text)  # ë””ë²„ê¹…ìš©
            result["detail"] = detail
            
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    def _parse_pr_detail(self, pr_number: str, page_text: str) -> Dict:
        """í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ PR ìƒì„¸ ì •ë³´ íŒŒì‹± (ì—¬ëŸ¬ í˜ì´ì§€ ì§€ì›)"""
        detail = {}
        
        # PR ë²ˆí˜¸ íŒ¨í„´ìœ¼ë¡œ ì‹œì‘ì  ì°¾ê¸°
        pr_num = pr_number.replace("PR-", "")
        
        # í•´ë‹¹ PRì˜ í…ìŠ¤íŠ¸ ì„¹ì…˜ ì¶”ì¶œ (ë‹¤ìŒ PRê¹Œì§€)
        # í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´ (Page XXX of XXXX)ë„ ë¬´ì‹œí•˜ë„ë¡ ê°œì„ 
        pr_section_pattern = rf'PR[-\s]?{pr_num}[:\s]*(.+?)(?=\n\s*\d+\.\d+\.\d+\.\d+\.\d+\.\s*PR[-\s]?\d|$)'
        section_match = re.search(pr_section_pattern, page_text, re.DOTALL | re.IGNORECASE)
        
        if section_match:
            section_text = section_match.group(1)
        else:
            section_text = page_text
        
        # í˜ì´ì§€ ë¨¸ë¦¬ë§/ê¼¬ë¦¬ë§ ì œê±° (ì—¬ëŸ¬ íŒ¨í„´)
        # 1. "2300 Release Notes Summary X.X.X-SPXX Release" íŒ¨í„´
        section_text = re.sub(r'\n?2300 Release Notes Summary[^\n]*\n', '\n', section_text, flags=re.IGNORECASE)
        # 2. "Page XXX of XXXX" íŒ¨í„´
        section_text = re.sub(r'\n?Page \d+ of \d+\n?', '\n', section_text, flags=re.IGNORECASE)
        # 3. "Lam Research CONFIDENTIAL" íŒ¨í„´
        section_text = re.sub(r'\n?Lam Research CONFIDENTIAL[^\n]*\n', '\n', section_text, flags=re.IGNORECASE)
        # 4. ì—°ì†ëœ ë¹ˆ ì¤„ ì •ë¦¬
        section_text = re.sub(r'\n{3,}', '\n\n', section_text)
        
        # PR ìœ í˜• ê°ì§€ (New Feature vs Issue Fix)
        pr_position = page_text.find(f"PR-{pr_num}")
        if pr_position == -1:
            pr_position = page_text.find(pr_num)
        pr_type = self._detect_pr_type(page_text, pr_position) if pr_position >= 0 else 'unknown'
        detail["pr_type"] = pr_type
        detail["pr_type_label"] = "New Feature" if pr_type == 'new_feature' else ("Issue Fix" if pr_type == 'issue_fix' else "Unknown")
        
        # â˜…â˜…â˜… ë¨¼ì € í‘œ í˜•ì‹ íŒŒì‹± ì‹œë„ (Release Notes Summary í˜•ì‹) â˜…â˜…â˜…
        # í˜•ì‹: ê° ì—´ì´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„ë¨
        # Area
        # Module  
        # Function (ì—¬ëŸ¬ ì¤„ì¼ ìˆ˜ ìˆìŒ)
        # PR-XXXXXX â€“ Description
        # Solution
        
        # PR ë²ˆí˜¸ ìœ„ì¹˜ ì°¾ê¸°
        pr_pos = re.search(rf'PR[-\s]?{pr_num}', page_text, re.IGNORECASE)
        if pr_pos:
            # PR ë²ˆí˜¸ ì• 400ì ë‚´ì—ì„œ Affected Function ì¶”ì¶œ
            start_pos = max(0, pr_pos.start() - 400)
            before_pr_text = page_text[start_pos:pr_pos.start()]
            
            # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬ëœ ê° ì¤„ í™•ì¸ (ì—­ìˆœ)
            lines = [l.strip() for l in before_pr_text.split('\n') if l.strip()]
            
            # ì´ì „ PRê¹Œì§€ì˜ í…ìŠ¤íŠ¸ ì œê±°
            clean_lines = []
            for line in reversed(lines):
                # ì´ì „ PR íŒ¨í„´ì´ë©´ ì¤‘ë‹¨
                if re.match(r'^PR[-\s]?\d{6}', line) or re.search(r'PR[-\s]?\d{6}', line):
                    break
                # í—¤ë”ë‚˜ ë¬´ê´€í•œ í…ìŠ¤íŠ¸ ì œì™¸
                if line in ['Module', 'Module Type', 'Affected', 'Function', 'Issue', 'Solution', 
                            'Affected Function', 'Issue Description']:
                    continue
                # Solution ê´€ë ¨ í…ìŠ¤íŠ¸ë©´ ì¤‘ë‹¨ (ì´ì „ PRì˜ solution)
                if line.startswith('The software has been') or 'has been changed' in line.lower():
                    break
                clean_lines.insert(0, line)
            
            # Affected Function ì¶”ì¶œ - ë§ˆì§€ë§‰ ì˜ë¯¸ìˆëŠ” ì¤„ë“¤ í•©ì¹˜ê¸°
            # clean_linesì—ì„œ 'All' ì´í›„ì˜ ì¤„ë“¤ì´ Affected Function
            affected_parts = []
            found_all = False
            for line in clean_lines:
                if line == 'All':
                    found_all = True
                    continue
                if found_all and line not in ['All', 'N/A', '-', 'All C', 'All G', 'Series']:
                    if not re.match(r'^[\d\.]+$', line) and not line.startswith('The '):
                        affected_parts.append(line)
            
            if affected_parts:
                # ì—¬ëŸ¬ ì¤„ì„ ê³µë°±ìœ¼ë¡œ í•©ì¹˜ê¸°
                detail["affected_function"] = ' '.join(affected_parts[-3:])[:100]  # ìµœëŒ€ 3ì¤„
            else:
                # fallback: ë§ˆì§€ë§‰ ì˜ë¯¸ìˆëŠ” ì¤„
                for line in reversed(clean_lines[-5:]):
                    if len(line) > 2 and line not in ['All', 'N/A', '-', 'All C', 'All G', 'Series', 'All All']:
                        if not re.match(r'^[\d\.]+$', line) and not line.startswith('The '):
                            detail["affected_function"] = line[:100]
                            break
        
        # PR ì„¤ëª… ì¶”ì¶œ (Issue Description)
        pr_desc_match = re.search(rf'PR[-\s]?{pr_num}[\sâ€“\-:]+([^\.]+\.)', page_text, re.IGNORECASE)
        if pr_desc_match:
            desc_text = pr_desc_match.group(1).strip()
            # "â€“" ë’¤ì˜ ì‹¤ì œ ì„¤ëª… ì¶”ì¶œ
            if desc_text.startswith('â€“') or desc_text.startswith('-'):
                desc_text = desc_text[1:].strip()
            if len(desc_text) > 10:
                detail["issue_description"] = desc_text[:300]
                detail["title"] = desc_text[:100]
        
        # Solution ì¶”ì¶œ - PR ë²ˆí˜¸ ì´í›„ì˜ í…ìŠ¤íŠ¸ì—ì„œë§Œ ê²€ìƒ‰
        if pr_pos:
            # PR ë²ˆí˜¸ ì´í›„ 600ì ë‚´ì—ì„œ solution ì°¾ê¸°
            after_pr_text = page_text[pr_pos.start():pr_pos.start()+600]
            # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€ê²½ (PDF í…ìŠ¤íŠ¸ëŠ” ì¤„ë°”ê¿ˆì´ ë§ìŒ)
            after_pr_text_normalized = re.sub(r'\s+', ' ', after_pr_text)
            
            # "The software has been changed" íŒ¨í„´ (ì¤„ë°”ê¿ˆ ì²˜ë¦¬ë¨)
            solution_match = re.search(r'(The software has been changed[^\.]+\.)', after_pr_text_normalized, re.IGNORECASE)
            if solution_match:
                detail["solution"] = solution_match.group(1).strip()[:200]
            
            # ëŒ€ì•ˆ íŒ¨í„´: "has been" + changed/fixed/updated
            if not detail.get("solution"):
                alt_solution = re.search(r'([A-Z][^\.]*has been (?:changed|fixed|updated|modified|corrected)[^\.]+\.)', after_pr_text_normalized, re.IGNORECASE)
                if alt_solution:
                    detail["solution"] = alt_solution.group(1).strip()[:200]
        
        # â˜…â˜…â˜… ìƒì„¸ í˜•ì‹ íŒŒì‹± (Component:, Module: ë“± í—¤ë”ê°€ ìˆëŠ” ê²½ìš°) â˜…â˜…â˜…
        
        # Title ì¶”ì¶œ (PR ë²ˆí˜¸ ë°”ë¡œ ë’¤ì˜ í…ìŠ¤íŠ¸) - ì´ë¯¸ ìœ„ì—ì„œ ì¶”ì¶œ ì•ˆëìœ¼ë©´
        if not detail.get("title"):
            title_match = re.search(rf'PR[-\s]?{pr_num}[:\s]*([^\n]+)', page_text, re.IGNORECASE)
            if title_match:
                detail["title"] = title_match.group(1).strip()
        
        # Component ì¶”ì¶œ - í•­ìƒ ì¶”ì¶œ ì‹œë„
        comp_match = re.search(r'Component[:\s]*\n?([A-Za-z][^\n]+)', section_text, re.IGNORECASE)
        if comp_match:
            comp_val = comp_match.group(1).strip()
            # "PM", "Module" ë“± ë¶ˆí•„ìš”í•œ ì ‘ë¯¸ì‚¬ ì œê±°
            if not comp_val.lower().startswith('module'):
                detail["component"] = comp_val
                # Affected Functionì´ ì—†ìœ¼ë©´ Component ì‚¬ìš©
                if not detail.get("affected_function"):
                    detail["affected_function"] = comp_val[:80]
        
        # Module ì¶”ì¶œ
        module_match = re.search(r'(?<!Module )Module[:\s]*\n?([A-Za-z0-9][^\n]+)', section_text, re.IGNORECASE)
        if module_match:
            val = module_match.group(1).strip()
            # Module Typeì´ ì•„ë‹Œ ê²½ìš°ë§Œ
            if not val.lower().startswith('type'):
                detail["module"] = val
                # Componentê°€ ì—†ìœ¼ë©´ Moduleì„ Componentë¡œ ì‚¬ìš©
                if not detail.get("component"):
                    detail["component"] = val
        
        # Affected Function ì¶”ì¶œ (í—¤ë” ë‹¤ìŒ ì¤„ì˜ ì‹¤ì œ ê°’)
        af_match = re.search(r'Affected Function[:\s]*\n([^\n]+)', section_text, re.IGNORECASE)
        if af_match:
            val = af_match.group(1).strip()
            # í˜ì´ì§€ ì •ë³´ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
            if not re.match(r'^\d+ Release Notes|^Page \d+|^Lam Research', val, re.IGNORECASE):
                detail["affected_function"] = val
        # ëŒ€ì•ˆ: ê°™ì€ ì¤„ì— ê°’ì´ ìˆëŠ” ê²½ìš°
        if not detail.get("affected_function"):
            af_match2 = re.search(r'Affected Function[:\s]+([A-Za-z][^\n]+)', section_text, re.IGNORECASE)
            if af_match2:
                val = af_match2.group(1).strip()
                if not re.match(r'^\d+ Release Notes|^Page \d+|^Lam Research', val, re.IGNORECASE):
                    detail["affected_function"] = val
        
        # History ì¶”ì¶œ (ë‹¤ìŒ ì„¹ì…˜ê¹Œì§€)
        history_match = re.search(
            r'History\s*\n(.+?)(?=Benefits|Description|CV\s*\(|Factory Automation|$)', 
            section_text, re.DOTALL | re.IGNORECASE
        )
        if history_match:
            history_text = history_match.group(1).strip()
            history_text = re.sub(r'\s+', ' ', history_text)
            detail["history"] = history_text
        
        # Benefits ì¶”ì¶œ (í˜ì´ì§€ ì •ë³´ ì œì™¸)
        benefits_match = re.search(
            r'Benefits\s*\n(.+?)(?=Description|CV\s*\(|History|Factory Automation|Recipe Parameter|UI Changes|Alarm|\d+\.\d+\.\d+\.\d+\.\d+\.|$)', 
            section_text, re.DOTALL | re.IGNORECASE
        )
        if benefits_match:
            benefits_text = benefits_match.group(1).strip()
            # í˜ì´ì§€ ì •ë³´ ì œê±°
            benefits_text = re.sub(r'2300 Release Notes Summary[^\n]*', '', benefits_text)
            benefits_text = re.sub(r'Page \d+ of \d+', '', benefits_text)
            benefits_text = re.sub(r'Lam Research CONFIDENTIAL[^\n]*', '', benefits_text)
            benefits_text = re.sub(r'\s+', ' ', benefits_text).strip()
            if benefits_text:
                detail["benefits"] = benefits_text
        
        # Description ì¶”ì¶œ (New Feature ì„¹ì…˜)
        desc_match = re.search(
            r'Description\s*\n(.+?)(?=CV\s*\(|Factory Automation|Recipe Parameter|UI Changes|Alarm|History|Benefits|\d+\.\d+\.\d+\.\d+\.\d+\.|$)', 
            section_text, re.DOTALL | re.IGNORECASE
        )
        if desc_match:
            desc_text = desc_match.group(1).strip()
            # í˜ì´ì§€ ì •ë³´ ì œê±°
            desc_text = re.sub(r'2300 Release Notes Summary[^\n]*', '', desc_text)
            desc_text = re.sub(r'Page \d+ of \d+', '', desc_text)
            desc_text = re.sub(r'Lam Research CONFIDENTIAL[^\n]*', '', desc_text)
            desc_text = re.sub(r'\s+', ' ', desc_text).strip()
            if desc_text:
                detail["description"] = desc_text
        
        # ===== Problem Report ì„¹ì…˜ í•„ë“œ (Issue Description, Root Cause, Solution) =====
        
        # Issue Description ì¶”ì¶œ
        issue_desc_match = re.search(
            r'Issue Description\s*\n(.+?)(?=Root Cause|Solution|CV\s*\(|Factory Automation|\d+\.\d+\.\d+\.\d+\.\d+\.|$)', 
            section_text, re.DOTALL | re.IGNORECASE
        )
        if issue_desc_match:
            issue_text = issue_desc_match.group(1).strip()
            # í˜ì´ì§€ ì •ë³´ ì œê±°
            issue_text = re.sub(r'2300 Release Notes Summary[^\n]*', '', issue_text)
            issue_text = re.sub(r'Page \d+ of \d+', '', issue_text)
            issue_text = re.sub(r'Lam Research CONFIDENTIAL[^\n]*', '', issue_text)
            issue_text = re.sub(r'\s+', ' ', issue_text).strip()
            if issue_text:
                detail["issue_description"] = issue_text
        
        # Root Cause ì¶”ì¶œ
        root_cause_match = re.search(
            r'Root Cause\s*\n(.+?)(?=Solution|CV\s*\(|Factory Automation|Recipe Parameter|\d+\.\d+\.\d+\.\d+\.\d+\.|$)', 
            section_text, re.DOTALL | re.IGNORECASE
        )
        if root_cause_match:
            root_cause_text = root_cause_match.group(1).strip()
            # í˜ì´ì§€ ì •ë³´ ì œê±°
            root_cause_text = re.sub(r'2300 Release Notes Summary[^\n]*', '', root_cause_text)
            root_cause_text = re.sub(r'Page \d+ of \d+', '', root_cause_text)
            root_cause_text = re.sub(r'Lam Research CONFIDENTIAL[^\n]*', '', root_cause_text)
            root_cause_text = re.sub(r'\s+', ' ', root_cause_text).strip()
            detail["root_cause"] = root_cause_text
        
        # Solution ì¶”ì¶œ (í—¤ë” í˜•ì‹ - Component:, Module: ë“±ì´ ìˆëŠ” ìƒì„¸ PDFìš©)
        # â˜… í‘œ í˜•ì‹ì—ì„œ ì´ë¯¸ solutionì„ ì°¾ì•˜ìœ¼ë©´ ë®ì–´ì“°ì§€ ì•ŠìŒ
        if not detail.get("solution"):
            solution_match = re.search(
                r'Solution\s*\n(.+?)(?=CV\s*\(|Factory Automation|Recipe Parameter|UI Changes|Alarm|\d+\.\d+\.\d+\.\d+\.\d+\.|$)', 
                section_text, re.DOTALL | re.IGNORECASE
            )
            if solution_match:
                solution_text = solution_match.group(1).strip()
                # í˜ì´ì§€ ì •ë³´ ì œê±°
                solution_text = re.sub(r'2300 Release Notes Summary[^\n]*', '', solution_text)
                solution_text = re.sub(r'Page \d+ of \d+', '', solution_text)
                solution_text = re.sub(r'Lam Research CONFIDENTIAL[^\n]*', '', solution_text)
                solution_text = re.sub(r'\s+', ' ', solution_text).strip()
                if solution_text:
                    detail["solution"] = solution_text
        
        # ===== Solution and Benefit í†µí•© í•„ë“œ (UI í‘œì‹œìš©) =====
        # - New Feature: Benefits ì‚¬ìš©
        # - Issue Fix: Solution ì‚¬ìš©
        if pr_type == 'new_feature':
            detail["solution_or_benefit"] = detail.get("benefits", "")
            detail["solution_or_benefit_label"] = "Benefits"
        else:  # issue_fix or unknown
            detail["solution_or_benefit"] = detail.get("solution", "")
            detail["solution_or_benefit_label"] = "Solution"
        
        # ===== Issue Description í†µí•© í•„ë“œ (UI í‘œì‹œìš©) =====
        # - New Feature: Description ì‚¬ìš©
        # - Issue Fix: Issue Description ì‚¬ìš©
        if pr_type == 'new_feature':
            detail["issue_or_description"] = detail.get("description", "")
        else:
            detail["issue_or_description"] = detail.get("issue_description", detail.get("description", ""))
        
        # ===== í…Œì´ë¸” íŒŒì‹± (ëª¨ë“  í…Œì´ë¸” íƒ€ì… í†µí•© ì²˜ë¦¬) =====
        
        # Factory Automation Changes í…Œì´ë¸” (ID Type í—¤ë” í¬í•¨)
        fa_pattern = r'Factory Automation\s*(?:Changes|Interface)?\s*\n(?:ID Type|Name).*?Action\s*\n(.+?)(?=CV\s*\(Configurable|Recipe Parameter|UI\s*Changes|Alarm|$)'
        fa_match = re.search(fa_pattern, section_text, re.IGNORECASE | re.DOTALL)
        if fa_match:
            fa_text = fa_match.group(1).strip()
            if fa_text and len(fa_text) > 5:
                detail["factory_automation_changes"] = self._parse_fa_table(fa_text)
        
        # CV (Configurable Variable) Changes í…Œì´ë¸” - ëª¨ë“  CV í…Œì´ë¸” ì°¾ê¸°
        # ì¢…ë£Œ ì¡°ê±´: ë‹¤ë¥¸ ì„¹ì…˜ ì‹œì‘, ì„¹ì…˜ ë²ˆí˜¸(7.X), ë˜ëŠ” í…Œì´ë¸” ë
        cv_pattern = r'CV\s*\(Configurable Variable\)\s*Changes\s*\n(?:Name\s+Description.*?Action\s*\n)?(.+?)(?=Factory Automation|Recipe Parameter|UI\s*Changes|Alarm|CV\s*\(Configurable|\n\d+\.\d+\.?\s*\n|$)'
        cv_matches = list(re.finditer(cv_pattern, section_text, re.IGNORECASE | re.DOTALL))
        if cv_matches:
            all_cv_html = []
            for i, cv_match in enumerate(cv_matches):
                cv_text = cv_match.group(1).strip()
                if cv_text and len(cv_text) > 5:
                    cv_html = self._parse_cv_table(cv_text, target_pr=pr_number)
                    all_cv_html.append(cv_html)
            if all_cv_html:
                detail["cv_changes"] = '\n'.join(all_cv_html)
        
        # Recipe Parameter Changes í…Œì´ë¸”
        rp_pattern = r'Recipe Parameter\s*Changes\s*\n(?:Name\s+Description.*?Action\s*\n)?(.+?)(?=Factory Automation|CV\s*\(|UI\s*Changes|Alarm|\n\d+\.\d+\.?\s*\n|$)'
        rp_match = re.search(rp_pattern, section_text, re.IGNORECASE | re.DOTALL)
        if rp_match:
            rp_text = rp_match.group(1).strip()
            if rp_text and len(rp_text) > 5:
                detail["recipe_parameter_changes"] = self._parse_cv_table(rp_text, target_pr=pr_number)
        
        # UI Changes í…Œì´ë¸”
        ui_pattern = r'UI\s*Changes\s*\n(?:Name\s+Description.*?Action\s*\n)?(.+?)(?=Factory Automation|CV\s*\(|Recipe Parameter|Alarm|\n\d+\.\d+\.?\s*\n|$)'
        ui_match = re.search(ui_pattern, section_text, re.IGNORECASE | re.DOTALL)
        if ui_match:
            ui_text = ui_match.group(1).strip()
            if ui_text and len(ui_text) > 5:
                detail["ui_changes"] = self._parse_cv_table(ui_text, target_pr=pr_number)
        
        # Alarm Changes í…Œì´ë¸” (Alarm ID Severity Description Recovery í—¤ë”)
        alarm_pattern = r'Alarm\s*(?:changes|Changes|modifications)?\s*\n(?:Alarm\s*ID|ID|Name).*?Action\s*\n(.+?)(?=Factory Automation|CV\s*\(|Recipe Parameter|UI\s*Changes|$)'
        alarm_match = re.search(alarm_pattern, section_text, re.IGNORECASE | re.DOTALL)
        if alarm_match:
            alarm_text = alarm_match.group(1).strip()
            if alarm_text and len(alarm_text) > 5:
                detail["alarm_changes"] = self._parse_alarm_table(alarm_text)
        
        return detail
    
    def _parse_fa_table(self, fa_text: str) -> str:
        """Factory Automation Changes í…Œì´ë¸”ì„ HTMLë¡œ ë³€í™˜
        
        í—¤ë”: ID Type | Variable ID | Description | Old Values | New Values | Action
        """
        lines = [l.strip() for l in fa_text.split('\n') if l.strip()]
        
        if not lines:
            return f'<pre style="background:#f5f5f5;padding:10px;border-radius:5px;font-size:12px;">{fa_text}</pre>'
        
        # action í‚¤ì›Œë“œ ìœ„ì¹˜ ì°¾ê¸°
        action_keywords = ['modified', 'added', 'removed', 'new', 'deleted']
        
        html = '<table style="width:100%;border-collapse:collapse;font-size:12px;margin-top:5px;">'
        html += '<thead><tr style="background:#e8f4f8;">'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:left;width:10%;">ID Type</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:10%;">Variable ID</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:left;width:40%;">Description</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:12%;">Old Values</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:12%;">New Values</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:10%;">Action</th>'
        html += '</tr></thead><tbody>'
        
        # ê° í•­ëª© íŒŒì‹± (CEID / SVID ë¡œ ì‹œì‘í•˜ëŠ” íŒ¨í„´)
        i = 0
        while i < len(lines):
            line = lines[i]
            
            # ID Type ì‹œì‘ (CEID, SVID ë“±)
            if line.upper() in ['CEID', 'SVID', 'DCID', 'VID']:
                id_type = line
                variable_id = ''
                description = ''
                old_val = ''
                new_val = ''
                action = ''
                
                # ë‹¤ìŒ ì¤„ë“¤ì—ì„œ ì •ë³´ ì¶”ì¶œ
                j = i + 1
                while j < len(lines):
                    next_line = lines[j]
                    
                    # action í‚¤ì›Œë“œë©´ í•­ëª© ì¢…ë£Œ
                    if next_line.lower() in action_keywords:
                        action = next_line
                        j += 1
                        break
                    # ë‹¤ìŒ ID Typeì´ë©´ ì¢…ë£Œ
                    elif next_line.upper() in ['CEID', 'SVID', 'DCID', 'VID']:
                        break
                    # ìˆ«ìë©´ Variable ID (ë³´í†µ 0)
                    elif next_line.isdigit() and not variable_id:
                        variable_id = next_line
                    # ë‚˜ë¨¸ì§€ëŠ” Description
                    else:
                        if description:
                            description += ' ' + next_line
                        else:
                            description = next_line
                    j += 1
                
                # í–‰ ì¶”ê°€
                action_color = '#d4edda' if action.lower() == 'added' else ('#fff3cd' if action.lower() == 'modified' else '#f8d7da' if action.lower() in ['removed', 'deleted'] else '')
                html += f'<tr>'
                html += f'<td style="border:1px solid #ccc;padding:6px;">{id_type}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;">{variable_id}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;">{description}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;">{old_val}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;">{new_val}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;background:{action_color}">{action}</td>'
                html += '</tr>'
                
                i = j
            else:
                i += 1
        
        html += '</tbody></table>'
        return html
    
    def _parse_alarm_table(self, alarm_text: str) -> str:
        """Alarm Changes í…Œì´ë¸”ì„ HTMLë¡œ ë³€í™˜
        
        í—¤ë”: Alarm ID | Severity | Description | Recovery | Old Value | New Value | Action
        """
        lines = [l.strip() for l in alarm_text.split('\n') if l.strip()]
        
        if not lines:
            return f'<pre style="background:#f5f5f5;padding:10px;border-radius:5px;font-size:12px;">{alarm_text}</pre>'
        
        action_keywords = ['modified', 'added', 'removed', 'new', 'deleted']
        severity_keywords = ['error', 'warning', 'info', 'critical']
        
        html = '<table style="width:100%;border-collapse:collapse;font-size:12px;margin-top:5px;">'
        html += '<thead><tr style="background:#ffe6e6;">'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:8%;">Alarm ID</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:10%;">Severity</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:left;width:35%;">Description</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:left;width:20%;">Recovery</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:9%;">Old Value</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:9%;">New Value</th>'
        html += '<th style="border:1px solid #ccc;padding:6px;text-align:center;width:9%;">Action</th>'
        html += '</tr></thead><tbody>'
        
        # ê° Alarm í•­ëª© íŒŒì‹± (ìˆ«ì ID ë˜ëŠ” Severityë¡œ ì‹œì‘)
        i = 0
        while i < len(lines):
            line = lines[i]
            
            # Alarm ID (ìˆ«ì) ë˜ëŠ” Severityë¡œ ì‹œì‘
            if line.isdigit() or line.lower() in severity_keywords:
                alarm_id = line if line.isdigit() else '0'
                severity = '' if line.isdigit() else line
                description = ''
                recovery = ''
                old_val = ''
                new_val = ''
                action = ''
                
                j = i + 1
                in_recovery = False
                
                while j < len(lines):
                    next_line = lines[j]
                    
                    # action í‚¤ì›Œë“œë©´ í•­ëª© ì¢…ë£Œ
                    if next_line.lower() in action_keywords:
                        action = next_line
                        j += 1
                        break
                    # Severity í‚¤ì›Œë“œ
                    elif next_line.lower() in severity_keywords and not severity:
                        severity = next_line
                    # ë‹¤ìŒ Alarm (ìˆ«ì ID)ì´ë©´ ì¢…ë£Œ
                    elif next_line.isdigit() and description:
                        break
                    # Recovery ê´€ë ¨ í‚¤ì›Œë“œ
                    elif 'Acknowle' in next_line or 'Restart' in next_line or 'Suppress' in next_line:
                        in_recovery = True
                        if recovery:
                            recovery += ' ' + next_line
                        else:
                            recovery = next_line
                    elif in_recovery and next_line not in severity_keywords:
                        # Recovery ê³„ì†
                        recovery += ' ' + next_line
                        if 'restart' in next_line.lower():
                            in_recovery = False
                    else:
                        # Description
                        if description:
                            description += ' ' + next_line
                        else:
                            description = next_line
                    j += 1
                
                # í–‰ ì¶”ê°€
                severity_color = '#f8d7da' if severity.lower() == 'error' else ('#fff3cd' if severity.lower() == 'warning' else '')
                action_color = '#d4edda' if action.lower() == 'added' else ('#fff3cd' if action.lower() == 'modified' else '#f8d7da' if action.lower() in ['removed', 'deleted'] else '')
                
                html += f'<tr>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;">{alarm_id}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;background:{severity_color}">{severity}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;">{description}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;font-size:11px;">{recovery}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;">{old_val}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;">{new_val}</td>'
                html += f'<td style="border:1px solid #ccc;padding:6px;text-align:center;background:{action_color}">{action}</td>'
                html += '</tr>'
                
                i = j
            else:
                i += 1
        
        html += '</tbody></table>'
        return html
    
    def _parse_cv_table(self, cv_text: str, target_pr: str = None) -> str:
        """CV Changes í…ìŠ¤íŠ¸ë¥¼ HTML í…Œì´ë¸”ë¡œ ë³€í™˜ (ê°œì„ ëœ ë²„ì „)
        
        PDFì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ êµ¬ì¡° ë¬¸ì œ í•´ê²°:
        1. í˜ì´ì§€ í—¤ë”/í‘¸í„°ê°€ ì¤‘ê°„ì— ì‚½ì…ë¨ â†’ ì œê±°
        2. í…Œì´ë¸” í—¤ë”ê°€ ë°˜ë³µë¨ (Name Description...) â†’ ì œê±°
        3. í…Œì´ë¸” êµ¬ì¡°: Name | Description | Old Value | New Value | Action
        4. Descriptionì— "min = X, max = Y, default = Z" íŒ¨í„´ í¬í•¨
        5. Action: added, modified, removed, deleted, new
        
        í•µì‹¬ ê°œì„ ì‚¬í•­:
        - ë³€ìˆ˜ëª… íŒ¨í„´ (CamelCase, underscore) ì •í™•íˆ íƒì§€
        - Description ì‹œì‘ì„ ì˜ì–´ ë¬¸ì¥ ì‹œì‘ íŒ¨í„´ìœ¼ë¡œ êµ¬ë¶„ (This, The, A, Supports, etc.)
        - target_pr ì§€ì • ì‹œ í•´ë‹¹ PR ê´€ë ¨ í•­ëª©ë§Œ í•„í„°ë§
        """
        
        # 0. í˜ì´ì§€ í—¤ë”/í‘¸í„° ì œê±° (ë¨¼ì € ì²˜ë¦¬)
        cv_text = re.sub(r'Page\s+\d+\s+of\s+\d+', '', cv_text, flags=re.IGNORECASE)
        cv_text = re.sub(r'2300 Release Notes Summary[^\n]*', '', cv_text, flags=re.IGNORECASE)
        cv_text = re.sub(r'Lam Research CONFIDENTIAL[^\n]*', '', cv_text, flags=re.IGNORECASE)
        
        # ë°˜ë³µëœ í…Œì´ë¸” í—¤ë” ì œê±°
        cv_text = re.sub(r'Name\s*\nDescription\s*\nOld\s*Value\s*\nNew\s*Value\s*\nAction\s*\n?', '', cv_text)
        cv_text = re.sub(r'Name\s*\nDescription\s*\nOld\s*\nValue\s*\nNew\s*\nValue\s*\nAction\s*\n?', '', cv_text)
        cv_text = re.sub(r'NameDescriptionOld\s*Value\s*New\s*Value\s*Action', '', cv_text, flags=re.IGNORECASE)
        cv_text = re.sub(r'\n{2,}', '\n', cv_text)
        
        action_keywords = ['modified', 'added', 'removed', 'new', 'deleted']
        
        # ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ê³  ë¹ˆ ì¤„ ì œê±°
        lines = [l.strip() for l in cv_text.split('\n') if l.strip()]
        lines = [l for l in lines if not re.match(r'^(Page\s+\d+|2300 Release|Lam Research)', l, re.IGNORECASE)]
        
        # ì„¹ì…˜ ë²ˆí˜¸(7.4. ë“±)ê°€ ë‚˜ì˜¤ë©´ ê·¸ ì´ì „ê¹Œì§€ë§Œ ì²˜ë¦¬
        section_break_idx = None
        for i, line in enumerate(lines):
            # ì„¹ì…˜ ë²ˆí˜¸ íŒ¨í„´ (7.4., 8.1. ë“±)
            if re.match(r'^\d+\.\d+\.?\s*$', line):
                section_break_idx = i
                break
        if section_break_idx is not None:
            lines = lines[:section_break_idx]
        
        # í—¤ë” í–‰ ìŠ¤í‚µ
        start_idx = 0
        for i, line in enumerate(lines):
            # íŒ¨í„´ 1: í•œ ì¤„ì— ëª¨ë“  í—¤ë”ê°€ ìˆëŠ” ê²½ìš°
            if 'Name' in line and 'Description' in line and 'Action' in line:
                start_idx = i + 1
                break
            # íŒ¨í„´ 2: ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ ìˆëŠ” ê²½ìš° - "Action"ì´ ë‹¨ë…ìœ¼ë¡œ ìˆëŠ” ì¤„ ì°¾ê¸°
            if line.lower() == 'action' and i < 10:
                # ì´ì „ ì¤„ë“¤ì— Name, Description ë“±ì´ ìˆëŠ”ì§€ í™•ì¸
                prev_lines = ' '.join(lines[max(0, i-6):i]).lower()
                if 'name' in prev_lines and 'description' in prev_lines:
                    start_idx = i + 1
                    break
        
        lines = lines[start_idx:]
        
        if not lines:
            return f'<pre style="background:#f5f5f5;padding:10px;border-radius:5px;font-size:12px;white-space:pre-wrap;">{cv_text}</pre>'
        
        # 2. ê° CV í•­ëª© íŒŒì‹± - action í‚¤ì›Œë“œ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
        current_row_lines = []
        rows_data = []
        
        for line in lines:
            current_row_lines.append(line)
            
            # í˜„ì¬ ì¤„ì´ action í‚¤ì›Œë“œë¡œ ëë‚˜ë©´ í•˜ë‚˜ì˜ í–‰ ì™„ì„±
            if line.lower() in action_keywords:
                if current_row_lines:
                    row_text = ' '.join(current_row_lines)
                    rows_data.append(row_text)
                    current_row_lines = []
        
        # ë§ˆì§€ë§‰ ë‚¨ì€ ì¤„ë“¤ ì²˜ë¦¬
        if current_row_lines:
            row_text = ' '.join(current_row_lines)
            if any(kw in row_text.lower() for kw in action_keywords):
                rows_data.append(row_text)
        
        if not rows_data:
            return f'<pre style="background:#f5f5f5;padding:10px;border-radius:5px;font-size:12px;white-space:pre-wrap;">{cv_text}</pre>'
        
        # 3. ê° í–‰ì—ì„œ Name, Description, Old Value, New Value, Action ì¶”ì¶œ
        cv_entries = []
        
        # Description ì‹œì‘ì„ ë‚˜íƒ€ë‚´ëŠ” ì˜ì–´ ë¬¸ì¥ ì‹œì‘ íŒ¨í„´
        description_start_words = [
            'this', 'the', 'a', 'an', 'when', 'if', 'used', 'uses', 'enables', 
            'specifies', 'defines', 'determines', 'indicates', 'controls', 'sets',
            'supports', 'holds', 'stores', 'represents', 'provides', 'allows',
            'configures', 'manages', 'handles', 'facilitates', 'contains', 'loads',
            'extended', 'corrected', 'updated', 'ensures', 'validates', 'represents'
        ]
        
        # target_pr ìˆ«ìë§Œ ì¶”ì¶œ (PR-198877 -> 198877)
        target_pr_num = None
        if target_pr:
            target_pr_num = re.sub(r'[^0-9]', '', target_pr)
        
        for row_text in rows_data:
            # ë‹¤ë¥¸ PR ë²ˆí˜¸ê°€ í¬í•¨ëœ í–‰ í•„í„°ë§
            if target_pr_num:
                # í–‰ì—ì„œ PR ë²ˆí˜¸ ì°¾ê¸° (PR-XXXXXX ë˜ëŠ” PR- XXXXXX íŒ¨í„´)
                pr_in_row = re.search(r'PR[-\s]*(\d{5,6})', row_text, re.IGNORECASE)
                if pr_in_row:
                    row_pr_num = pr_in_row.group(1)
                    # í˜„ì¬ ê²€ìƒ‰ PRê³¼ ë‹¤ë¥´ë©´ ê±´ë„ˆëœ€
                    if row_pr_num != target_pr_num:
                        continue
                    # PR ë²ˆí˜¸ ë¶€ë¶„ ì œê±° (Nameì— í¬í•¨ë˜ì§€ ì•Šë„ë¡)
                    row_text = re.sub(r'PR[-\s]*\d{5,6}\s*', '', row_text).strip()
            
            # Action ì¶”ì¶œ (ë§ˆì§€ë§‰ ë‹¨ì–´)
            action_match = re.search(r'\b(modified|added|removed|new|deleted)\s*$', row_text, re.IGNORECASE)
            if not action_match:
                continue
            
            action = action_match.group(1)
            remaining = row_text[:action_match.start()].strip()
            
            # NA NA ê°’ ì¶”ì¶œ (Old Value, New Valueê°€ ë‘˜ ë‹¤ NAì¸ ê²½ìš°)
            old_value = ''
            new_value = ''
            na_pattern = re.search(r'\s+NA\s+NA\s*$', remaining, re.IGNORECASE)
            if na_pattern:
                old_value = 'NA'
                new_value = 'NA'
                remaining = remaining[:na_pattern.start()].strip()
            
            # íŒ¨í„´ 1: "min = X, max = Y, default = Z"
            value_pattern = re.search(r'(min\s*=\s*[\d.]+,?\s*max\s*=\s*[\d.]+,?\s*default\s*=\s*[\w.]+)', remaining, re.IGNORECASE)
            if value_pattern:
                new_value = value_pattern.group(1)
                remaining = remaining[:value_pattern.start()].strip()
            else:
                # íŒ¨í„´ 2: "default = X" ë§Œ ìˆëŠ” ê²½ìš°
                default_pattern = re.search(r'(default\s*=\s*[\w.]+)\s*$', remaining, re.IGNORECASE)
                if default_pattern:
                    new_value = default_pattern.group(1)
                    remaining = remaining[:default_pattern.start()].strip()
            
            # ê°œì„ ëœ Nameê³¼ Description ë¶„ë¦¬ ë¡œì§
            words = remaining.split()
            name_parts = []
            description_start_idx = 0
            
            for i, word in enumerate(words):
                # Description ì‹œì‘ ê°ì§€: ì˜ì–´ ë¬¸ì¥ ì‹œì‘ ë‹¨ì–´
                if word.lower() in description_start_words:
                    description_start_idx = i
                    break
                
                # ë³€ìˆ˜ëª… ì¡°ê° íŒë‹¨
                is_varname_part = False
                
                if i == 0:
                    # ì²« ë‹¨ì–´: ë³€ìˆ˜ëª… íŒ¨í„´ ì—¬ë¶€ íŒë‹¨
                    # - ì–¸ë”ìŠ¤ì½”ì–´ í¬í•¨ (RFM_, ESC_ ë“±)
                    # - ëŒ€ë¬¸ìë¡œ ì‹œì‘ (ConfigEditor, Process ë“±)
                    # - CamelCase íŒ¨í„´ (loadConfig, restoreCVs ë“±) - ëŒ€ë¬¸ì í¬í•¨
                    # - ìˆ«ì í¬í•¨ (State1, Mode2 ë“±)
                    has_underscore = '_' in word
                    starts_upper = len(word) > 0 and word[0].isupper()
                    has_camelcase = any(c.isupper() for c in word) or any(c.isdigit() for c in word)
                    is_description_word = word.lower() in description_start_words
                    
                    if not is_description_word and (has_underscore or starts_upper or has_camelcase):
                        is_varname_part = True
                else:
                    # í›„ì† ë‹¨ì–´: CamelCase ì¡°ê° íŒë‹¨
                    
                    # ì†Œë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ì§§ì€ ë‹¨ì–´ (CamelCaseì˜ ì¤‘ê°„ ì¡°ê°)
                    if len(word) > 0 and word[0].islower() and len(word) <= 25:
                        # Description ì‹œì‘ ë‹¨ì–´ê°€ ì•„ë‹ˆë©´ ë³€ìˆ˜ëª… ì¡°ê°
                        if word.lower() not in description_start_words:
                            is_varname_part = True
                    # ìˆ«ìë¡œ ì‹œì‘ (State1, State2 ë“±)
                    elif len(word) > 0 and word[0].isdigit() and len(word) <= 5:
                        is_varname_part = True
                    # ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ê³  ì–¸ë”ìŠ¤ì½”ì–´ í¬í•¨ (ë³€ìˆ˜ëª… ì—°ì†)
                    elif '_' in word:
                        is_varname_part = True
                    # ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ì§§ì€ ë‹¨ì–´ (CamelCase ì¡°ê°ì¼ ìˆ˜ ìˆìŒ)
                    elif len(word) > 0 and word[0].isupper() and len(word) <= 20:
                        # í•˜ì§€ë§Œ Description ì‹œì‘ ë‹¨ì–´ë©´ ì¤‘ë‹¨
                        if word.lower() in description_start_words:
                            description_start_idx = i
                            break
                        is_varname_part = True
                
                if is_varname_part:
                    name_parts.append(word)
                    description_start_idx = i + 1
                else:
                    break
            
            # ë³€ìˆ˜ëª… ì¡°ë¦½ (ê³µë°± ì—†ì´ í•©ì¹˜ê¸°)
            name = ''.join(name_parts)
            
            # Description ì¶”ì¶œ (ë³€ìˆ˜ëª… ì´í›„ì˜ ëª¨ë“  í…ìŠ¤íŠ¸)
            if description_start_idx < len(words):
                description = ' '.join(words[description_start_idx:])
            else:
                description = ''
            
            # ë³€ìˆ˜ëª…ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ì²« ë²ˆì§¸ ë‹¨ì–´ ì‚¬ìš©
            if len(name) < 3:
                name = words[0] if words else ''
                description = ' '.join(words[1:]) if len(words) > 1 else ''
            
            cv_entries.append({
                'name': name,
                'description': description,
                'old_value': old_value,
                'new_value': new_value,
                'action': action
            })
        
        # 4. HTML í…Œì´ë¸” ìƒì„±
        if not cv_entries:
            return f'<pre style="background:#f5f5f5;padding:10px;border-radius:5px;font-size:12px;white-space:pre-wrap;">{cv_text}</pre>'
        
        html = '<table style="width:100%;border-collapse:collapse;font-size:12px;margin-top:5px;">'
        html += '<thead><tr style="background:#e8f4f8;">'
        html += '<th style="border:1px solid #ccc;padding:8px;text-align:left;width:30%;">Name</th>'
        html += '<th style="border:1px solid #ccc;padding:8px;text-align:left;width:25%;">Description</th>'
        html += '<th style="border:1px solid #ccc;padding:8px;text-align:center;width:10%;">Old Value</th>'
        html += '<th style="border:1px solid #ccc;padding:8px;text-align:center;width:25%;">New Value</th>'
        html += '<th style="border:1px solid #ccc;padding:8px;text-align:center;width:10%;">Action</th>'
        html += '</tr></thead><tbody>'
        
        for entry in cv_entries:
            action_lower = entry['action'].lower()
            if action_lower in ['added', 'new']:
                action_color = '#28a745'
                action_bg = '#e8f5e9'
            elif action_lower in ['removed', 'deleted']:
                action_color = '#dc3545'
                action_bg = '#ffebee'
            else:
                action_color = '#007bff'
                action_bg = '#e3f2fd'
            
            html += f'<tr>'
            html += f'<td style="border:1px solid #ddd;padding:8px;font-family:monospace;font-weight:bold;background:#fafafa;word-break:break-all;">{entry["name"]}</td>'
            html += f'<td style="border:1px solid #ddd;padding:8px;">{entry["description"]}</td>'
            html += f'<td style="border:1px solid #ddd;padding:8px;text-align:center;font-family:monospace;background:#fff8e1;">{entry["old_value"]}</td>'
            html += f'<td style="border:1px solid #ddd;padding:8px;text-align:center;font-family:monospace;background:#e8f5e9;">{entry["new_value"]}</td>'
            html += f'<td style="border:1px solid #ddd;padding:8px;text-align:center;color:{action_color};font-weight:bold;background:{action_bg};">{entry["action"]}</td>'
            html += f'</tr>'
        
        html += '</tbody></table>'
        return html
    
    def search_pr_by_keyword(self, keyword: str, limit: int = 10) -> Dict:
        """í‚¤ì›Œë“œ ê¸°ë°˜ PR ê²€ìƒ‰ - í…Œì´ë¸” í˜•íƒœë¡œ ê²°ê³¼ ë°˜í™˜
        
        Args:
            keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ì˜ˆ: "Bias RF", "chamber", "alarm")
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
            - found: ê²°ê³¼ ê°œìˆ˜
            - keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            - results: PR ë¦¬ìŠ¤íŠ¸ (pr_number, sw_version, title, issue_description, solution ë“±)
            - html_table: HTML í…Œì´ë¸” í˜•íƒœì˜ ê²°ê³¼
        """
        if not self.db_path.exists():
            return {"found": 0, "error": "Index not built"}
        
        # FTS5 ì „ë¬¸ ê²€ìƒ‰ìœ¼ë¡œ í‚¤ì›Œë“œ í¬í•¨ í˜ì´ì§€ ì°¾ê¸°
        text_results = self.search_text(keyword, limit=limit * 3)  # ì¤‘ë³µ ê³ ë ¤í•˜ì—¬ ë” ë§ì´ ê²€ìƒ‰
        
        if not text_results:
            return {"found": 0, "keyword": keyword, "results": [], "html_table": ""}
        
        # ë°œê²¬ëœ í˜ì´ì§€ì—ì„œ PR ë²ˆí˜¸ ì¶”ì¶œ ë° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        seen_prs = set()
        pr_results = []
        
        for text_result in text_results:
            # í•´ë‹¹ í˜ì´ì§€ì˜ PRë“¤ ì°¾ê¸°
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT DISTINCT p.pr_number, f.sw_version, p.context, f.filename
                FROM pr_index p
                JOIN pdf_files f ON p.file_id = f.id
                WHERE f.filename = ? AND p.page_num = ?
                ORDER BY f.sw_version DESC
            """, (text_result["filename"], text_result["page"]))
            
            for row in cursor.fetchall():
                pr_num = row[0]
                if pr_num in seen_prs:
                    continue
                seen_prs.add(pr_num)
                
                # PR ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                pr_detail = self.get_pr_detail(pr_num)
                if pr_detail:
                    detail = pr_detail.get("detail", {})
                    pr_results.append({
                        "pr_number": pr_num,
                        "sw_version": pr_detail.get("sw_version", ""),
                        "title": detail.get("title", ""),
                        "affected_function": detail.get("affected_function", ""),
                        "issue_description": detail.get("issue_description", detail.get("description", "")),
                        "solution": detail.get("solution", detail.get("benefits", "")),
                        "context": row[2][:150] if row[2] else ""
                    })
                
                if len(pr_results) >= limit:
                    break
            
            conn.close()
            
            if len(pr_results) >= limit:
                break
        
        # HTML í…Œì´ë¸” ìƒì„±
        html_table = self._format_keyword_search_table(keyword, pr_results)
        
        return {
            "found": len(pr_results),
            "keyword": keyword,
            "results": pr_results,
            "html_table": html_table
        }
    
    def _format_keyword_search_table(self, keyword: str, results: List[Dict]) -> str:
        """í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ HTML í…Œì´ë¸”ë¡œ í¬ë§·íŒ…"""
        if not results:
            return f"<p>ğŸ” '<b>{keyword}</b>'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.</p>"
        
        html = f'<div style="margin-bottom:10px;"><h3 style="margin:0 0 8px 0;color:#7c3aed;">ğŸ” "{keyword}" ê´€ë ¨ PR ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê±´)</h3></div>'
        html += '<table style="width:100%;border-collapse:collapse;font-size:14px;margin-bottom:10px;">'
        html += '<thead><tr style="background:linear-gradient(135deg,#7c3aed,#a855f7);color:white;">'
        html += '<th style="border:1px solid #6b21a8;padding:12px;text-align:left;width:12%;">PR Number</th>'
        html += '<th style="border:1px solid #6b21a8;padding:12px;text-align:left;width:10%;">SW Version</th>'
        html += '<th style="border:1px solid #6b21a8;padding:12px;text-align:left;width:25%;">Affected Function / Title</th>'
        html += '<th style="border:1px solid #6b21a8;padding:12px;text-align:left;width:28%;">Issue / Description</th>'
        html += '<th style="border:1px solid #6b21a8;padding:12px;text-align:left;width:25%;">Solution / Benefit</th>'
        html += '</tr></thead><tbody>'
        
        for idx, pr in enumerate(results):
            bg_color = "#faf5ff" if idx % 2 == 0 else "#ffffff"
            
            # íƒ€ì´í‹€ ë˜ëŠ” Affected Function í‘œì‹œ
            title_display = pr.get("affected_function") or pr.get("title") or "-"
            if len(title_display) > 150:
                title_display = title_display[:147] + "..."
            
            # Issue/Description (í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸)
            issue = pr.get("issue_description") or "-"
            if len(issue) > 200:
                issue = issue[:197] + "..."
            if keyword:
                for kw in keyword.split():
                    issue = re.sub(f'({re.escape(kw)})', r'<mark style="background:#fef08a;">\1</mark>', issue, flags=re.IGNORECASE)
            
            # Solution/Benefit
            solution = pr.get("solution") or "-"
            if len(solution) > 200:
                solution = solution[:197] + "..."
            
            html += f'<tr style="background:{bg_color};">'
            html += f'<td style="border:1px solid #ddd;padding:10px;font-family:monospace;font-weight:bold;color:#7c3aed;"><a href="#" onclick="searchPR(\'{pr["pr_number"]}\');return false;" style="color:#7c3aed;text-decoration:underline;">{pr["pr_number"]}</a></td>'
            html += f'<td style="border:1px solid #ddd;padding:10px;font-family:monospace;">{pr.get("sw_version", "-")}</td>'
            html += f'<td style="border:1px solid #ddd;padding:10px;">{title_display}</td>'
            html += f'<td style="border:1px solid #ddd;padding:10px;color:#555;">{issue}</td>'
            html += f'<td style="border:1px solid #ddd;padding:10px;color:#065f46;">{solution}</td>'
            html += '</tr>'
        
        html += '</tbody></table>'
        html += '<p style="font-size:12px;color:#666;margin:5px 0;">ğŸ’¡ PR ë²ˆí˜¸ë¥¼ í´ë¦­í•˜ë©´ ìƒì„¸ ì •ë³´ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Click PR number for details.</p>'
        html += '<script>function searchPR(prNum){const input=document.getElementById("chat-input");if(input){input.value=prNum;const form=input.closest("form");if(form){form.dispatchEvent(new Event("submit"));}}}</script>'
        
        return html

    def find_similar_prs_fast(self, pr_title: str, pr_number: str = None, limit: int = 3) -> Dict:
        """PR ì œëª© ê¸°ë°˜ ìœ ì‚¬ PR ë¹ ë¥¸ ê²€ìƒ‰ - íƒ€ì„ì•„ì›ƒ ë°©ì§€ìš© ê°„ì†Œí™” ë²„ì „
        
        find_similar_prsì˜ ê°„ì†Œí™” ë²„ì „ìœ¼ë¡œ:
        - ê²€ìƒ‰ í‚¤ì›Œë“œ ìˆ˜ ì œí•œ (5ê°œ)
        - FTS5 ê²€ìƒ‰ ê²°ê³¼ ì œí•œ (15ê°œ)
        - ê°„ì†Œí™”ëœ ì ìˆ˜ ê³„ì‚°
        
        Args:
            pr_title: ê²€ìƒ‰í•  PR ì œëª©
            pr_number: ì›ë³¸ PR ë²ˆí˜¸ (ê²°ê³¼ì—ì„œ ì œì™¸)
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.db_path.exists():
            return {"found": 0, "error": "Index not built"}
        
        # ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords_from_title(pr_title)
        
        if not keywords:
            return {"found": 0, "original_title": pr_title, "similar_prs": [], "keywords": []}
        
        # í‚¤ì›Œë“œ ì œí•œ (ë¹ ë¥¸ ê²€ìƒ‰)
        combo_keywords = [k for k in keywords if ' ' in k][:2]  # ì¡°í•© 2ê°œ
        single_keywords = [k for k in keywords if ' ' not in k][:3]  # ë‹¨ì¼ 3ê°œ
        search_keywords = combo_keywords + single_keywords
        
        # PR í›„ë³´ ìˆ˜ì§‘
        candidate_prs = {}
        
        for keyword in search_keywords:
            text_results = self.search_text(keyword, limit=15)  # ê²°ê³¼ ì œí•œ
            
            for text_result in text_results:
                conn = sqlite3.connect(str(self.db_path))
                cursor = conn.cursor()
                
                cursor.execute("""
                    SELECT DISTINCT p.pr_number, f.sw_version, p.context
                    FROM pr_index p
                    JOIN pdf_files f ON p.file_id = f.id
                    WHERE f.filename = ? AND p.page_num = ?
                    LIMIT 5
                """, (text_result["filename"], text_result["page"]))
                
                for row in cursor.fetchall():
                    found_pr = row[0]
                    
                    if pr_number and found_pr == f"PR-{pr_number.replace('PR-', '')}":
                        continue
                    
                    if found_pr not in candidate_prs:
                        pr_detail = self.get_pr_detail(found_pr)
                        if pr_detail:
                            detail = pr_detail.get("detail", {})
                            candidate_prs[found_pr] = {
                                "pr_number": found_pr,
                                "sw_version": pr_detail.get("sw_version", ""),
                                "title": detail.get("title", ""),
                                "affected_function": detail.get("affected_function", ""),
                                "issue_description": detail.get("issue_description", detail.get("description", "")),
                                "solution": detail.get("solution", detail.get("benefits", "")),
                                "matched_keywords": [],
                                "relevance_score": 0
                            }
                
                conn.close()
                
                # í›„ë³´ 10ê°œ ìˆ˜ì§‘ í›„ ì¤‘ë‹¨
                if len(candidate_prs) >= 10:
                    break
            
            if len(candidate_prs) >= 10:
                break
        
        # ê°„ì†Œí™”ëœ ì ìˆ˜ ê³„ì‚°
        for pr_num, pr_info in candidate_prs.items():
            full_text = (pr_info.get("title", "") + " " + pr_info.get("issue_description", "")).lower()
            score = 0
            matched = []
            
            for kw in search_keywords:
                kw_lower = kw.lower()
                if kw_lower in full_text:
                    matched.append(kw)
                    score += 20 if ' ' in kw else 5  # ì¡°í•© 20ì , ë‹¨ì¼ 5ì 
            
            pr_info["matched_keywords"] = matched
            pr_info["relevance_score"] = score
        
        # ì ìˆ˜ ê¸°ë°˜ ì •ë ¬ ë° í•„í„°
        sorted_results = sorted(
            [p for p in candidate_prs.values() if p["relevance_score"] > 0],
            key=lambda x: x["relevance_score"],
            reverse=True
        )[:limit]
        
        final_results = [{
            "pr_number": p["pr_number"],
            "sw_version": p["sw_version"],
            "title": p["title"],
            "affected_function": p["affected_function"],
            "issue_description": p["issue_description"],
            "solution": p["solution"],
            "matched_keywords": p["matched_keywords"],
            "relevance_score": p["relevance_score"]
        } for p in sorted_results]
        
        return {
            "found": len(final_results),
            "original_title": pr_title,
            "keywords": search_keywords,
            "similar_prs": final_results
        }
    
    def find_similar_prs(self, pr_title: str, pr_number: str = None, limit: int = 5, 
                         use_hybrid: bool = True, strictness: int = 2) -> Dict:
        """PR ì œëª© ê¸°ë°˜ ìœ ì‚¬ PR ê²€ìƒ‰ - SWRNì—ì„œ ë¹„ìŠ·í•œ ë¬¸ì œ/í•´ê²°ì±… ì°¾ê¸°
        
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìš°ì„  ì‹œë„, ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ í´ë°±
        
        Args:
            pr_title: ê²€ìƒ‰í•  PR ì œëª©
            pr_number: ì›ë³¸ PR ë²ˆí˜¸ (ê²°ê³¼ì—ì„œ ì œì™¸)
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            use_hybrid: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ True)
            strictness: í•„í„°ë§ ì—„ê²©ë„ 0-3 (ê¸°ë³¸ 2)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìš°ì„  ì‹œë„
        if use_hybrid and HYBRID_SEARCH_AVAILABLE:
            try:
                result = self.find_similar_prs_hybrid(pr_title, pr_number, limit, strictness)
                if result.get("found", 0) > 0:
                    return result
                # í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ ì—†ìœ¼ë©´ strictness ë‚®ì¶°ì„œ ì¬ì‹œë„
                if strictness > 0:
                    result = self.find_similar_prs_hybrid(pr_title, pr_number, limit, strictness=0)
                    if result.get("found", 0) > 0:
                        return result
            except Exception as e:
                print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±: {e}")
        
        # ê¸°ì¡´ ê²€ìƒ‰ ë¡œì§ (í´ë°±)
        return self._find_similar_prs_legacy(pr_title, pr_number, limit)
    
    def _find_similar_prs_legacy(self, pr_title: str, pr_number: str = None, limit: int = 5) -> Dict:
        """ê¸°ì¡´ ë°©ì‹ ìœ ì‚¬ PR ê²€ìƒ‰ (ë ˆê±°ì‹œ)
        
        ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜:
        1. WHERE + WHAT í‚¤ì›Œë“œ ì¶”ì¶œ
        2. ê° í‚¤ì›Œë“œë¡œ FTS5 ê²€ìƒ‰
        3. ê²€ìƒ‰ëœ PRì˜ title/issue_descriptionì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ì¦
        4. ë§¤ì¹­ ì ìˆ˜ ê¸°ë°˜ ì •ë ¬ (ì¡°í•© í‚¤ì›Œë“œ > ë‹¨ì¼ í‚¤ì›Œë“œ)
        """
        if not self.db_path.exists():
            return {"found": 0, "error": "Index not built"}
        
        # ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self._extract_keywords_from_title(pr_title)
        
        if not keywords:
            return {"found": 0, "original_title": pr_title, "similar_prs": [], "keywords": []}
        
        # í‚¤ì›Œë“œë¥¼ ì¡°í•© í‚¤ì›Œë“œì™€ ë‹¨ì¼ í‚¤ì›Œë“œë¡œ ë¶„ë¦¬
        combo_keywords = [k for k in keywords if ' ' in k]  # WHERE+WHAT ì¡°í•©
        single_keywords = [k for k in keywords if ' ' not in k]  # ë‹¨ì¼ í‚¤ì›Œë“œ
        
        # PR í›„ë³´ ìˆ˜ì§‘ (PR ìƒì„¸ ì •ë³´ì™€ í•¨ê»˜)
        candidate_prs = {}  # pr_number -> {pr_info, matched_keywords, scores}
        
        # ê²€ìƒ‰í•  í‚¤ì›Œë“œ ëª©ë¡ (ì¡°í•© ìš°ì„ , ìµœëŒ€ 7ê°œ)
        search_keywords = combo_keywords[:4] + single_keywords[:3]
        
        for keyword in search_keywords:
            text_results = self.search_text(keyword, limit=30)
            
            for text_result in text_results:
                conn = sqlite3.connect(str(self.db_path))
                cursor = conn.cursor()
                
                # í•´ë‹¹ í˜ì´ì§€ì˜ PRë“¤ ì°¾ê¸°
                cursor.execute("""
                    SELECT DISTINCT p.pr_number, f.sw_version, p.context
                    FROM pr_index p
                    JOIN pdf_files f ON p.file_id = f.id
                    WHERE f.filename = ? AND p.page_num = ?
                """, (text_result["filename"], text_result["page"]))
                
                for row in cursor.fetchall():
                    found_pr = row[0]
                    
                    # ì›ë³¸ PR ì œì™¸
                    if pr_number and found_pr == f"PR-{pr_number.replace('PR-', '')}":
                        continue
                    
                    # ìƒˆ PRì´ë©´ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    if found_pr not in candidate_prs:
                        pr_detail = self.get_pr_detail(found_pr)
                        if pr_detail:
                            detail = pr_detail.get("detail", {})
                            candidate_prs[found_pr] = {
                                "pr_number": found_pr,
                                "sw_version": pr_detail.get("sw_version", ""),
                                "title": detail.get("title", ""),
                                "affected_function": detail.get("affected_function", ""),
                                "issue_description": detail.get("issue_description", detail.get("description", "")),
                                "solution": detail.get("solution", detail.get("benefits", "")),
                                "matched_combo_keywords": set(),
                                "matched_single_keywords": set(),
                                "title_matches": set(),
                                "content_matches": set(),
                                "relevance_score": 0
                            }
                
                conn.close()
        
        # ê° PR í›„ë³´ì— ëŒ€í•´ ì‹¤ì œ í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ì¦
        for pr_num, pr_info in candidate_prs.items():
            # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì œëª© + ì´ìŠˆì„¤ëª…)
            title_text = (pr_info.get("title", "") + " " + pr_info.get("affected_function", "")).lower()
            content_text = (pr_info.get("issue_description", "") + " " + pr_info.get("solution", "")).lower()
            full_text = title_text + " " + content_text
            
            total_score = 0
            exact_match_count = 0  # ì™„ì „ ë§¤ì¹­ ê°œìˆ˜
            
            # ì¡°í•© í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ì¦ (ë†’ì€ ì ìˆ˜)
            for combo_kw in combo_keywords[:4]:
                combo_lower = combo_kw.lower()
                # ì¡°í•© ì „ì²´ê°€ ë§¤ì¹­ë˜ë©´ ë†’ì€ ì ìˆ˜
                if combo_lower in full_text:
                    pr_info["matched_combo_keywords"].add(combo_kw)
                    exact_match_count += 1
                    if combo_lower in title_text:
                        pr_info["title_matches"].add(combo_kw)
                        total_score += 30  # ì œëª©ì—ì„œ ì¡°í•© ë§¤ì¹­ = ìµœê³ ì 
                    else:
                        pr_info["content_matches"].add(combo_kw)
                        total_score += 15  # ë‚´ìš©ì—ì„œ ì¡°í•© ë§¤ì¹­
                else:
                    # ì¡°í•©ì˜ ê°œë³„ ë‹¨ì–´ ë§¤ì¹­ í™•ì¸ - ë‚®ì€ ì ìˆ˜
                    combo_parts = combo_kw.lower().split()
                    parts_matched = sum(1 for part in combo_parts if part in full_text)
                    if parts_matched >= len(combo_parts) * 0.6:  # 60% ì´ìƒ ë§¤ì¹­ í•„ìš”
                        pr_info["matched_combo_keywords"].add(f"{combo_kw}*")  # ë¶€ë¶„ ë§¤ì¹­ í‘œì‹œ
                        # ë¶€ë¶„ ë§¤ì¹­ì€ ë‚®ì€ ì ìˆ˜ (ì™„ì „ ë§¤ì¹­ì˜ 1/3)
                        partial_score = parts_matched * 2
                        total_score += partial_score
            
            # ë‹¨ì¼ í‚¤ì›Œë“œ ë§¤ì¹­ ê²€ì¦
            for single_kw in single_keywords[:5]:
                single_lower = single_kw.lower()
                if single_lower in full_text:
                    pr_info["matched_single_keywords"].add(single_kw)
                    if single_lower in title_text:
                        pr_info["title_matches"].add(single_kw)
                        total_score += 8  # ì œëª©ì—ì„œ ë‹¨ì¼ í‚¤ì›Œë“œ ë§¤ì¹­
                    else:
                        pr_info["content_matches"].add(single_kw)
                        total_score += 3  # ë‚´ìš©ì—ì„œ ë‹¨ì¼ í‚¤ì›Œë“œ ë§¤ì¹­
            
            # ì™„ì „ ë§¤ì¹­ì´ ìˆìœ¼ë©´ ë³´ë„ˆìŠ¤ ì ìˆ˜
            if exact_match_count > 0:
                total_score += exact_match_count * 10
            
            pr_info["relevance_score"] = total_score
            pr_info["exact_match_count"] = exact_match_count
        
        # ì ìˆ˜ê°€ ìˆëŠ” PRë§Œ í•„í„°ë§í•˜ê³  ì •ë ¬
        scored_prs = [
            pr_info for pr_info in candidate_prs.values() 
            if pr_info["relevance_score"] > 0 and (
                pr_info["matched_combo_keywords"] or pr_info["matched_single_keywords"]
            )
        ]
        
        # ì •ë ¬: ì™„ì „ ë§¤ì¹­ ê°œìˆ˜ > ì ìˆ˜ > ì œëª© ë§¤ì¹­ ê°œìˆ˜
        sorted_results = sorted(
            scored_prs, 
            key=lambda x: (
                x.get("exact_match_count", 0),  # ì™„ì „ ë§¤ì¹­ ìš°ì„ 
                x["relevance_score"],            # ì ìˆ˜
                len(x.get("title_matches", set()))  # ì œëª© ë§¤ì¹­ ê°œìˆ˜
            ), 
            reverse=True
        )[:limit]
        
        # ê²°ê³¼ í¬ë§·íŒ…
        final_results = []
        for pr_info in sorted_results:
            # ë§¤ì¹­ëœ í‚¤ì›Œë“œ í†µí•©
            all_matched = list(pr_info["matched_combo_keywords"]) + list(pr_info["matched_single_keywords"])
            title_matched = list(pr_info["title_matches"])
            
            final_results.append({
                "pr_number": pr_info["pr_number"],
                "sw_version": pr_info["sw_version"],
                "title": pr_info["title"],
                "affected_function": pr_info["affected_function"],
                "issue_description": pr_info["issue_description"],
                "solution": pr_info["solution"],
                "matched_keywords": all_matched,
                "title_matched_keywords": title_matched,  # ì œëª©ì—ì„œ ë§¤ì¹­ëœ í‚¤ì›Œë“œ
                "relevance_score": pr_info["relevance_score"]
            })
        
        return {
            "found": len(final_results),
            "original_title": pr_title,
            "keywords": keywords[:7],
            "combo_keywords": combo_keywords[:4],
            "single_keywords": single_keywords[:3],
            "similar_prs": final_results
        }
    
    def find_similar_prs_hybrid(self, pr_title: str, pr_number: str = None, limit: int = 5,
                               strictness: int = 2) -> Dict:
        """í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ìœ ì‚¬ PR ê²€ìƒ‰ - TF-IDF + ë™ì˜ì–´ + FTS5 ì¡°í•©
        
        ê°œì„ ëœ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸:
        1. ë™ì˜ì–´ í™•ì¥ (Synonym Expansion) - ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€
        2. FTS5 BM25 ê²€ìƒ‰ (Sparse Retrieval) - ë¹ ë¥¸ í›„ë³´ ì¶”ì¶œ
        3. TF-IDF ì¬ë­í‚¹ (Dense Reranking) - ì •ë°€ ìœ ì‚¬ë„ ê³„ì‚°
        4. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° - Î±Ã—BM25 + Î²Ã—TF-IDF + Î³Ã—keyword
        
        ì„±ëŠ¥: 400+ PDF ë¬¸ì„œì—ì„œ 50-100ms ì´ë‚´
        
        Args:
            pr_title: ê²€ìƒ‰í•  PR ì œëª©
            pr_number: ì›ë³¸ PR ë²ˆí˜¸ (ê²°ê³¼ì—ì„œ ì œì™¸)
            limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            strictness: í•„í„°ë§ ì—„ê²©ë„ (0-3)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í¬í•¨)
        """
        if not HYBRID_SEARCH_AVAILABLE:
            # í•˜ì´ë¸Œë¦¬ë“œ ì—”ì§„ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ í´ë°±
            return self._find_similar_prs_legacy(pr_title, pr_number, limit)
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ ì§€ì—° ì´ˆê¸°í™”
        if self._hybrid_engine is None:
            self._hybrid_engine = HybridPRSearchEngine(
                db_path=self.db_path,
                swrn_indexer=self
            )
            self._hybrid_engine.initialize()
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
        exclude_pr = f"PR-{pr_number.replace('PR-', '')}" if pr_number else None
        results = self._hybrid_engine.search_similar_prs(
            query=pr_title,
            exclude_pr=exclude_pr,
            limit=limit,
            strictness=strictness
        )
        
        # ê²°ê³¼ í¬ë§· ë³€í™˜ (ê¸°ì¡´ find_similar_prsì™€ í˜¸í™˜)
        # ë°°ì¹˜ë¡œ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (sw_version, context, pr_type)
        similar_prs = results.get("similar_prs", [])
        
        # AND ë§¤ì¹­ PRì„ ìš°ì„  ì •ë ¬ (is_and_matchê°€ Trueì¸ ê²ƒ ë¨¼ì €, ê·¸ ë‹¤ìŒ hybrid_score ìˆœ)
        similar_prs.sort(key=lambda x: (-1 if x.get("is_and_match") else 0, -x.get("hybrid_score", 0)))
        
        # PR ë²ˆí˜¸ ìˆ˜ì§‘
        pr_nums = [pr.get("pr_number", "").replace("PR-", "") for pr in similar_prs if pr.get("pr_number")]
        
        # ë°°ì¹˜ë¡œ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (pr_index + pdf_files JOIN)
        pr_info_map = {}
        if pr_nums and self.db_path.exists():
            try:
                import sqlite3
                conn = sqlite3.connect(str(self.db_path))
                cursor = conn.cursor()
                
                # pr_number ì•ì— PR- ë¶™ì–´ìˆì„ ìˆ˜ë„ ìˆê³  ì—†ì„ ìˆ˜ë„ ìˆìŒ
                pr_nums_with_prefix = [f"PR-{pn}" if not pn.startswith("PR-") else pn for pn in pr_nums]
                placeholders = ','.join(['?' for _ in pr_nums_with_prefix])
                
                cursor.execute(f"""
                    SELECT p.pr_number, f.sw_version, p.context, p.pr_type
                    FROM pr_index p
                    JOIN pdf_files f ON p.file_id = f.id
                    WHERE p.pr_number IN ({placeholders})
                """, pr_nums_with_prefix)
                
                for row in cursor.fetchall():
                    pr_num_clean = row[0].replace("PR-", "")
                    pr_type = row[3] if len(row) > 3 else 'unknown'
                    pr_info_map[pr_num_clean] = {
                        "sw_version": row[1] or "",
                        "context": row[2] or "",
                        "pr_type": pr_type
                    }
                conn.close()
            except Exception as e:
                print(f"âš ï¸ PR ê¸°ë³¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        
        formatted_results = []
        for pr in similar_prs:
            pr_num = pr.get("pr_number", "").replace("PR-", "")
            
            # ê¸°ë³¸ ì •ë³´ ë³´ì™„
            info = pr_info_map.get(pr_num, {})
            sw_version = info.get("sw_version", pr.get("sw_version", ""))
            context = info.get("context", pr.get("context", ""))
            pr_type = info.get("pr_type", pr.get("pr_type", "unknown"))
            
            # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (solution_or_benefit, issue_description ë“± í¬í•¨)
            solution_or_benefit = ""
            benefits = ""
            solution = ""
            affected_function = ""
            description = ""
            issue_description = ""
            try:
                pr_detail = self.get_pr_detail(pr_num)
                if pr_detail:
                    detail = pr_detail.get("detail", {})
                    solution_or_benefit = detail.get("solution_or_benefit", "")
                    benefits = detail.get("benefits", "")
                    solution = detail.get("solution", "")
                    affected_function = detail.get("affected_function", "")
                    description = detail.get("description", "")
                    issue_description = detail.get("issue_description", "")
                    # pr_typeë„ ìƒì„¸ ì •ë³´ì—ì„œ ê°€ì ¸ì˜´
                    if pr_type == 'unknown' and detail.get("pr_type"):
                        pr_type = detail.get("pr_type", pr_type)
            except Exception:
                pass
            
            # PR ìœ í˜• ë¼ë²¨ ìƒì„± (unknownë„ í‘œì‹œí•˜ì§€ë§Œ UIì—ì„œ ë‹¤ë¥´ê²Œ ì²˜ë¦¬ ê°€ëŠ¥)
            if pr_type == 'new_feature':
                pr_type_label = "New Feature"
            elif pr_type == 'issue_fix':
                pr_type_label = "Issue Fix"
            else:
                pr_type_label = ""  # unknownì€ ë¹ˆ ë¬¸ìì—´ë¡œ í‘œì‹œ (UIì—ì„œ ìˆ¨ê¸¸ ìˆ˜ ìˆìŒ)
            
            # Issue Description / Description ê²°ì • (PR íƒ€ì…ì— ë”°ë¼)
            # New Feature: description ì‚¬ìš©
            # Issue Fix: issue_description ì‚¬ìš©
            if pr_type == 'new_feature':
                issue_desc = description if description else issue_description
            else:
                issue_desc = issue_description if issue_description else description
            
            # ì—¬ì „íˆ ì—†ìœ¼ë©´ contextì—ì„œ ì¶”ì¶œ
            if not issue_desc:
                issue_desc = context[:200] + "..." if len(context) > 200 else context
            
            # ë§¤ì¹­ í‚¤ì›Œë“œ
            matched_kw = pr.get("matched_keywords", [])
            
            # Solution or Benefit ìµœì¢… ê²°ì • (ì´ë¯¸ ìƒì„¸ ì •ë³´ì—ì„œ ê°€ì ¸ì˜´, ì—†ìœ¼ë©´ pr_type ê¸°ë°˜ ì„ íƒ)
            if not solution_or_benefit:
                if pr_type == 'new_feature':
                    solution_or_benefit = benefits if benefits else solution
                else:
                    solution_or_benefit = solution if solution else benefits
            
            formatted_results.append({
                "pr_number": pr_num,
                "sw_version": sw_version,
                "title": pr.get("title", ""),
                "affected_function": affected_function,  # detailì—ì„œ ê°€ì ¸ì˜¨ ê°’ ì‚¬ìš©
                "issue_description": issue_desc,  # issue_or_description ê°’
                "description": description,  # New Featureìš© Description
                "issue_desc_raw": issue_description,  # Issue Fixìš© Issue Description ì›ë³¸
                "solution": solution,
                "benefits": benefits,
                "solution_or_benefit": solution_or_benefit,
                "matched_keywords": matched_kw,
                "relevance_score": int(pr.get("hybrid_score", 0) * 100),
                "hybrid_score": pr.get("hybrid_score", 0),
                "bm25_score": pr.get("bm25_norm", 0),
                "tfidf_score": pr.get("tfidf_score", 0),
                "pr_type": pr_type,
                "pr_type_label": pr_type_label,
                "is_and_match": pr.get("is_and_match", False)  # AND ë§¤ì¹­ ì—¬ë¶€
            })
        
        return {
            "found": len(formatted_results),
            "original_title": pr_title,
            "keywords": results.get("expanded_queries", [])[:7],
            "search_method": "hybrid",  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í‘œì‹œ
            "similar_prs": formatted_results
        }
    
    def rebuild_hybrid_index(self) -> bool:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (TF-IDF ìºì‹œ ê°±ì‹ )"""
        if not HYBRID_SEARCH_AVAILABLE:
            print("âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        if self._hybrid_engine is None:
            self._hybrid_engine = HybridPRSearchEngine(
                db_path=self.db_path,
                swrn_indexer=self
            )
        
        return self._hybrid_engine.initialize(force_rebuild=True)
    
    def _extract_keywords_from_title(self, title: str) -> List[str]:
        """PR ì œëª©/ì´ìŠˆì—ì„œ í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ (ë°˜ë„ì²´ ì¥ë¹„ SW ë„ë©”ì¸ íŠ¹í™”)
        
        í•µì‹¬ ì›ì¹™: WHERE(ì–´ë””ì—ì„œ) + WHAT(ë¬´ì—‡ì„) ì¡°í•©
        
        WHERE íŒ¨í„´ (ìœ„ì¹˜/ì»¨í…ìŠ¤íŠ¸):
        - ì¥ë¹„ëª…: Kiyo GX, Sensei, Akara, Vantex, Producer, Centris ë“±
        - í˜ì´ì§€ëª…: Recipe Page, Recipe Constant Page, Tempo Editor, Setup Page ë“±
        - ëª¨ë“ˆëª…: custom IO, process data, Factory Automation ë“±
        - ì‹œìŠ¤í…œ: UI session, alarm system, control module ë“±
        
        WHAT íŒ¨í„´ (ëŒ€ìƒ/ë™ì‘):
        - ë¬¸ì œ: termination, crash, error, mismatch, timeout ë“±
        - ëŒ€ìƒ: process time, Cancel button, SVID, parameter ë“±
        - ë™ì‘: Add, Remove, Update, stabilization ë“±
        
        ì˜ˆì‹œ:
        - "Actual process time is more progressed... in Kiyo GX" 
          â†’ WHERE: Kiyo GX, WHAT: process time
        - "Add Cancel button in the Tempo Editor page of the recipe page"
          â†’ WHERE: recipe page, Tempo Editor, WHAT: Cancel button
        """
        
        # ============================================================
        # WHERE ì¹´í…Œê³ ë¦¬ - ìœ„ì¹˜/ì»¨í…ìŠ¤íŠ¸ (ì–´ë””ì—ì„œ)
        # ============================================================
        
        # ì¥ë¹„/ì œí’ˆëª… (ë³µí•©ì–´ - ìš°ì„  ì¶”ì¶œ)
        equipment_patterns = [
            r'(?i)\b(Kiyo\s*(?:G?X|45|CX)?)\b',  # Kiyo GX, Kiyo CX, Kiyo45
            r'(?i)\b(Sensei)\b',
            r'(?i)\b(Akara)\b',
            r'(?i)\b(Vantex)\b',
            r'(?i)\b(Producer\s*(?:GT|SE|XP)?)\b',  # Producer GT, Producer SE
            r'(?i)\b(Centris\s*(?:Sym3|Tera)?)\b',  # Centris Sym3
            r'(?i)\b(Versys\s*(?:Metal|Kyo)?)\b',
            r'(?i)\b(Flex\s*(?:D|E|F)?)\b',
            r'(?i)\b(Vector\s*(?:ICP|Extreme)?)\b',
            r'(?i)\b(Coronus\s*(?:DX|HP)?)\b',
        ]
        
        # í˜ì´ì§€/í™”ë©´ëª… (ë³µí•©ì–´)
        page_patterns = [
            r'(?i)\b(Recipe\s+(?:Constant\s+)?Page)\b',
            r'(?i)\b(Tempo\s+Editor(?:\s+page)?)\b',
            r'(?i)\b(Setup\s+(?:Page|Screen|Dialog))\b',
            r'(?i)\b(Maintenance\s+(?:Page|Screen|Mode))\b',
            r'(?i)\b(Process\s+(?:Page|Monitor|Data|Summary))\b',
            r'(?i)\b(Alarm\s+(?:Page|List|Log|History))\b',
            r'(?i)\b(Config(?:uration)?\s+(?:Page|Screen|Dialog))\b',
            r'(?i)\b(Status\s+(?:Page|Bar|Panel))\b',
        ]
        
        # ëª¨ë“ˆ/ì‹œìŠ¤í…œëª… (ë³µí•©ì–´)
        module_patterns = [
            r'(?i)\b(custom\s+IO)\b',
            r'(?i)\b(Factory\s+Automation)\b',
            r'(?i)\b(process\s+data(?:\s+summ(?:ary)?)?)\b',
            r'(?i)\b(UI\s+session)\b',
            r'(?i)\b(control\s+(?:module|system))\b',
            r'(?i)\b(alarm\s+(?:system|module))\b',
            r'(?i)\b(recipe\s+(?:editor|manager))\b',
            r'(?i)\b(wafer\s+(?:handler|transfer))\b',
            r'(?i)\b(gas\s+(?:panel|system|box))\b',
            r'(?i)\b(RF\s+(?:generator|matcher|system))\b',
        ]
        
        # ë‹¨ì¼ ì¥ì†Œ í‚¤ì›Œë“œ
        where_single = {
            'chamber', 'slot', 'loadport', 'aligner', 'foup', 'cassette',
            'plc', 'controller', 'host', 'server', 'client',
            'terminal', 'console', 'editor', 'viewer', 'dialog'
        }
        
        # ============================================================
        # WHAT ì¹´í…Œê³ ë¦¬ - ëŒ€ìƒ/ë™ì‘ (ë¬´ì—‡ì„)
        # ============================================================
        
        # ê¸°ìˆ  ëŒ€ìƒ (ë³µí•©ì–´)
        target_patterns = [
            r'(?i)\b(process\s+(?:time|parameter|data))\b',
            r'(?i)\b(setpoint\s+time)\b',
            r'(?i)\b(stabilization\s+time)\b',
            r'(?i)\b(Cancel\s+button)\b',
            r'(?i)\b(OK\s+button)\b',
            r'(?i)\b(SVID\s*[\"\']?[\w]+[\"\']?)\b',  # SVID "name" ë˜ëŠ” SVID name
            r'(?i)\b(new\s+SVID)\b',
            r'(?i)\b(recipe\s+(?:step|constant|parameter))\b',
            r'(?i)\b(CV\s+(?:value|parameter|variable))\b',
            r'(?i)\b(alarm\s+(?:ID|code|message))\b',
            r'(?i)\b(error\s+(?:code|message|log))\b',
            r'(?i)\b(wear\s+compensation)\b',
            r'(?i)\b(RF\s+(?:power|bias|match))\b',
            r'(?i)\b(gas\s+(?:flow|pressure))\b',
            r'(?i)\b(temperature\s+(?:value|setpoint|control))\b',
            r'(?i)\b(pressure\s+(?:value|setpoint|control))\b',
        ]
        
        # ë™ì‘/ë¬¸ì œ (ë³µí•©ì–´)
        action_patterns = [
            r'(?i)\b(sudden\s+termination)\b',
            r'(?i)\b((?:UI|session)\s+termination)\b',
            r'(?i)\b(Add\s+(?:\w+\s+)?(?:button|SVID|parameter|field))\b',
            r'(?i)\b(Remove\s+(?:\w+\s+)?(?:button|SVID|parameter|field))\b',
            r'(?i)\b(parameter\s+(?:stabilization|validation|check))\b',
            r'(?i)\b((?:time(?:out)?|value)\s+mismatch)\b',
            r'(?i)\b((?:connection|communication)\s+(?:lost|error|fail))\b',
        ]
        
        # ì¦ìƒ/ì—ëŸ¬ í‚¤ì›Œë“œ
        symptoms = {
            'termination', 'crash', 'hang', 'freeze', 'frozen', 'stuck',
            'error', 'fail', 'failure', 'fault', 'timeout', 'mismatch',
            'overflow', 'underflow', 'interlock', 'alarm', 'warning',
            'disconnect', 'lost', 'missing', 'corrupt', 'invalid',
            'uhe', 'exception', 'grayout', 'lockup', 'spike', 'shift'
        }
        
        # ë™ì‘ í‚¤ì›Œë“œ (Action words - WHATì—ì„œ ì¤‘ìš”)
        actions = {
            'add', 'remove', 'update', 'modify', 'change', 'create', 'delete',
            'enable', 'disable', 'display', 'show', 'hide', 'request'
        }
        
        # ëŒ€ìƒ í‚¤ì›Œë“œ (ë‹¨ì¼)
        targets = {
            'button', 'svid', 'ceid', 'dcid', 'vid', 'parameter', 'variable',
            'time', 'value', 'step', 'recipe', 'alarm', 'page', 'screen',
            'module', 'component', 'function', 'feature', 'option', 'field'
        }
        
        # ============================================================
        # ë¶ˆìš©ì–´ (ì œì™¸)
        # ============================================================
        stopwords = {
            'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
            'should', 'may', 'might', 'must', 'shall', 'can', 'for', 'of', 'to',
            'in', 'on', 'at', 'by', 'with', 'from', 'as', 'into', 'through',
            'during', 'before', 'after', 'above', 'below', 'between', 'under',
            'over', 'up', 'down', 'about', 'this', 'that', 'these', 'those',
            'it', 'its', 'and', 'or', 'but', 'if', 'then', 'else', 'when',
            'where', 'which', 'who', 'what', 'how', 'why', 'not', 'no', 'yes',
            'all', 'any', 'some', 'every', 'each', 'few', 'more', 'most',
            'other', 'another', 'such', 'same', 'so', 'than', 'too', 'very',
            'just', 'only', 'also', 'even', 'still', 'already', 'yet', 'now',
            'here', 'there', 'pr', 'bug', 'fix', 'fixed', 'issue', 'problem',
            'both', 'particular', 'actual', 'into', 'request'
        }
        
        # ============================================================
        # í‚¤ì›Œë“œ ì¶”ì¶œ ë¡œì§
        # ============================================================
        
        found_where = []  # WHERE í‚¤ì›Œë“œ (ìœ„ì¹˜/ì»¨í…ìŠ¤íŠ¸)
        found_what = []   # WHAT í‚¤ì›Œë“œ (ëŒ€ìƒ/ë™ì‘)
        seen = set()
        
        # 1. ë³µí•© WHERE íŒ¨í„´ ì¶”ì¶œ (ì¥ë¹„ëª…, í˜ì´ì§€ëª…, ëª¨ë“ˆëª…)
        for pattern in equipment_patterns + page_patterns + module_patterns:
            matches = re.findall(pattern, title)
            for m in matches:
                match_clean = re.sub(r'\s+', ' ', m.strip())
                if match_clean.lower() not in seen:
                    found_where.append(match_clean)
                    seen.add(match_clean.lower())
        
        # 2. ë³µí•© WHAT íŒ¨í„´ ì¶”ì¶œ (ëŒ€ìƒ, ë™ì‘)
        for pattern in target_patterns + action_patterns:
            matches = re.findall(pattern, title)
            for m in matches:
                match_clean = re.sub(r'\s+', ' ', m.strip())
                if match_clean.lower() not in seen:
                    found_what.append(match_clean)
                    seen.add(match_clean.lower())
        
        # 3. ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ì‹ë³„ì ì¶”ì¶œ (SVID "TESRFWear...")
        quoted_ids = re.findall(r'["\']([A-Za-z][\w]+)["\']', title)
        for qid in quoted_ids:
            if qid.lower() not in seen and len(qid) > 3:
                found_what.append(qid)
                seen.add(qid.lower())
        
        # 4. ëŒ€ë¬¸ì ì•½ì–´/ì œí’ˆì½”ë“œ ì¶”ì¶œ (N120269, RF, SVID ë“±)
        # ìˆ«ì+ë¬¸ì ì½”ë“œ (N120269, PR123456 ë“±)
        codes = re.findall(r'\b([A-Z]\d{5,})\b', title)
        for code in codes:
            if code.lower() not in seen:
                found_where.append(code)
                seen.add(code.lower())
        
        # ëŒ€ë¬¸ì ì•½ì–´
        abbreviations = re.findall(r'\b([A-Z]{2,6})\b', title)
        for abbr in abbreviations:
            abbr_lower = abbr.lower()
            if abbr_lower not in seen and abbr_lower not in stopwords:
                # SVID, CEID ë“±ì€ WHAT, ê·¸ ì™¸ (RF, UI, IO)ëŠ” ì¼ë‹¨ ë³´ë¥˜
                if abbr_lower in {'svid', 'ceid', 'dcid', 'vid'}:
                    found_what.append(abbr)
                elif abbr_lower in {'rf', 'io', 'ui', 'cv', 'pm', 'fa'}:
                    found_where.append(abbr)
                else:
                    found_where.append(abbr)  # ê¸°íƒ€ ì•½ì–´ëŠ” WHEREë¡œ ê°€ì •
                seen.add(abbr_lower)
        
        # 5. ë‹¨ì¼ í‚¤ì›Œë“œ ë¶„ë¥˜
        all_words = re.findall(r'\b([A-Za-z]{3,})\b', title)
        
        for word in all_words:
            word_lower = word.lower()
            if word_lower in seen or word_lower in stopwords:
                continue
            
            # ì¦ìƒ/ì—ëŸ¬ â†’ WHAT
            if word_lower in symptoms:
                found_what.append(word)
                seen.add(word_lower)
            # ë™ì‘ â†’ WHAT
            elif word_lower in actions:
                found_what.append(word)
                seen.add(word_lower)
            # ëŒ€ìƒ â†’ WHAT  
            elif word_lower in targets:
                found_what.append(word)
                seen.add(word_lower)
            # ì¥ì†Œ â†’ WHERE
            elif word_lower in where_single:
                found_where.append(word)
                seen.add(word_lower)
        
        # 6. CamelCase ë¶„ë¦¬ëœ ê¸°ìˆ ìš©ì–´ ì¶”ì¶œ (TESRFWearCompansationFactorSlope)
        camel_matches = re.findall(r'\b([A-Z][a-z]+(?:[A-Z][a-z]+)+)\b', title)
        for cm in camel_matches:
            if cm.lower() not in seen:
                found_what.append(cm)
                seen.add(cm.lower())
        
        # ============================================================
        # ìµœì¢… í‚¤ì›Œë“œ ì¡°í•© ìƒì„± 
        # í•µì‹¬ ì›ì¹™: WHERE + WHAT ì¡°í•©ì´ ê²€ìƒ‰ì˜ í•µì‹¬ (ê°€ì¥ ì•ì— ë°°ì¹˜)
        # ìˆœì„œ: 1) WHERE+WHAT ì¡°í•© â†’ 2) WHAT ë‹¨ë… â†’ 3) WHERE ë‹¨ë… (ì‹ ë¢°ë„ ë‚®ìŒ)
        # ============================================================
        
        final_keywords = []
        combo_seen = set()
        
        # 1. WHERE + WHAT ì¡°í•© ìƒì„± (ìµœìš°ì„  - ê²€ìƒ‰ì˜ í•µì‹¬!)
        # ì˜ˆ: "Kiyo GX process time", "Sensei sudden termination", "process data new SVID"
        if found_where and found_what:
            # ì²« ë²ˆì§¸ WHERE + ì²« ë²ˆì§¸ WHAT ì¡°í•© (ê°€ì¥ ì¤‘ìš”í•œ ì¡°í•©)
            primary_combo = f"{found_where[0]} {found_what[0]}"
            final_keywords.append(primary_combo)
            combo_seen.add(primary_combo.lower())
            
            # ì¶”ê°€ ì¡°í•© (ìµœëŒ€ 2ê°œ ë”)
            for where in found_where[:2]:
                for what in found_what[:3]:
                    combo = f"{where} {what}"
                    if combo.lower() not in combo_seen:
                        final_keywords.append(combo)
                        combo_seen.add(combo.lower())
                    if len(final_keywords) >= 3:
                        break
                if len(final_keywords) >= 3:
                    break
        
        # 2. WHAT ë³µí•©ì–´ ì¶”ê°€ (ë¬¸ì œ/ëŒ€ìƒ - ì¤‘ìš”ë„ ë†’ìŒ)
        # ì˜ˆ: "process time", "sudden termination", "new SVID"
        for what in found_what:
            if ' ' in what and what.lower() not in combo_seen:  # ë³µí•©ì–´ ìš°ì„ 
                final_keywords.append(what)
                combo_seen.add(what.lower())
                if len(final_keywords) >= 5:
                    break
        
        # 3. WHAT ë‹¨ì¼ í‚¤ì›Œë“œ (ì‹ ë¢°ë„ ì¤‘ê°„)
        for what in found_what:
            if ' ' not in what and what.lower() not in combo_seen:
                final_keywords.append(what)
                combo_seen.add(what.lower())
                if len(final_keywords) >= 7:
                    break
        
        # 4. WHERE ë‹¨ë…ì€ ë§ˆì§€ë§‰ì— (ì‹ ë¢°ë„ ë‚®ìŒ - ë²”ìœ„ê°€ ë„ˆë¬´ ë„“ìŒ)
        # ì˜ˆ: "Kiyo GX" ë‹¨ë…ìœ¼ë¡œ ê²€ìƒ‰í•˜ë©´ ë„ˆë¬´ ë§ì€ ê²°ê³¼
        for where in found_where:
            if where.lower() not in combo_seen:
                final_keywords.append(where)
                combo_seen.add(where.lower())
                if len(final_keywords) >= 10:
                    break
        
        # 5. í‚¤ì›Œë“œê°€ ë„ˆë¬´ ì ìœ¼ë©´ ì¼ë°˜ ë‹¨ì–´ì—ì„œ ì¶”ê°€ (4ê¸€ì ì´ìƒ)
        if len(final_keywords) < 3:
            for word in all_words:
                word_lower = word.lower()
                if word_lower not in combo_seen and word_lower not in stopwords and len(word) >= 4:
                    final_keywords.append(word)
                    combo_seen.add(word_lower)
                    if len(final_keywords) >= 5:
                        break
        
        return final_keywords[:10]  # ìµœëŒ€ 10ê°œ í‚¤ì›Œë“œ
    
    def find_insights_for_open_prs(self, open_prs: List[Dict], limit_per_pr: int = 3) -> List[Dict]:
        """ì—¬ëŸ¬ Open PRì— ëŒ€í•´ SWRNì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¼ê´„ ê²€ìƒ‰
        
        Args:
            open_prs: PR ë¦¬ìŠ¤íŠ¸ [{"pr_number": "PR-123456", "title": "...", "days_open": 30}, ...]
            limit_per_pr: PRë‹¹ ìµœëŒ€ ìœ ì‚¬ PR ê°œìˆ˜
            
        Returns:
            ì¸ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        insights = []
        max_prs_to_process = 5  # íƒ€ì„ì•„ì›ƒ ë°©ì§€ë¥¼ ìœ„í•´ ìµœëŒ€ 5ê°œë§Œ ì²˜ë¦¬
        processed = 0
        
        for pr in open_prs:
            if processed >= max_prs_to_process:
                break
            
            pr_number = pr.get("pr_number", "")
            title = pr.get("title", "")
            days_open = pr.get("days_open", 0)
            
            if not title or len(title) < 10:  # ë„ˆë¬´ ì§§ì€ ì œëª© ìŠ¤í‚µ
                continue
            
            # ìœ ì‚¬ PR ê²€ìƒ‰ (ë¹ ë¥¸ ê²€ìƒ‰ ëª¨ë“œ)
            similar_result = self.find_similar_prs_fast(title, pr_number, limit=limit_per_pr)
            
            processed += 1
            
            if similar_result.get("found", 0) > 0:
                insights.append({
                    "open_pr": {
                        "pr_number": pr_number,
                        "title": title,
                        "days_open": days_open,
                        "status": pr.get("status", "")
                    },
                    "keywords": similar_result.get("keywords", []),
                    "similar_prs": similar_result.get("similar_prs", []),
                    "insight_summary": self._generate_insight_summary(pr, similar_result.get("similar_prs", []))
                })
        
        return insights
    
    def _generate_insight_summary(self, open_pr: Dict, similar_prs: List[Dict]) -> str:
        """ìœ ì‚¬ PR ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìš”ì•½ ìƒì„±"""
        if not similar_prs:
            return "ìœ ì‚¬í•œ í•´ê²° ì‚¬ë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        # í•´ê²°ì±…ì´ ìˆëŠ” PR í™•ì¸
        solutions = [p for p in similar_prs if p.get("solution")]
        
        if solutions:
            return f"SWRNì—ì„œ {len(similar_prs)}ê°œì˜ ìœ ì‚¬ PR ë°œê²¬. {len(solutions)}ê°œì—ì„œ í•´ê²°ì±… í™•ì¸ ê°€ëŠ¥."
        else:
            return f"SWRNì—ì„œ {len(similar_prs)}ê°œì˜ ìœ ì‚¬ PR ë°œê²¬. ìƒì„¸ ë‚´ìš© í™•ì¸ í•„ìš”."

    def get_stats(self) -> Dict:
        """ì¸ë±ìŠ¤ í†µê³„"""
        if not self.db_path.exists():
            return {"indexed": False}
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM pdf_files")
        file_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM pr_index")
        pr_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT pr_number) FROM pr_index")
        unique_prs = cursor.fetchone()[0]
        
        cursor.execute("SELECT SUM(page_count) FROM pdf_files")
        total_pages = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return {
            "indexed": True,
            "file_count": file_count,
            "total_pages": total_pages,
            "pr_entries": pr_count,
            "unique_prs": unique_prs,
            "db_size_mb": self.db_path.stat().st_size / 1024 / 1024
        }
    
    def format_pr_result(self, pr_number: str) -> str:
        """PR ê²€ìƒ‰ ê²°ê³¼ë¥¼ HTML í¬ë§·ìœ¼ë¡œ ë°˜í™˜"""
        result = self.get_pr_detail(pr_number)
        
        if not result:
            return f"ğŸ“‹ <b>{pr_number}</b>ëŠ” SWRNì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        html = f"""ğŸ“‹ <b>{result['pr_number']}</b> Release Notes ì •ë³´:<br><br>
<b>SW Version:</b> {result['sw_version']}<br>
<b>Source:</b> {result['filename']}<br>
<b>Page:</b> {result['page']}<br>"""
        
        if "detail" in result and result["detail"]:
            d = result["detail"]
            
            if d.get("title"):
                html += f"<br><b>ğŸ“Œ Title:</b> {d['title']}<br>"
            if d.get("component"):
                html += f"<b>ğŸ”§ Component:</b> {d['component']}<br>"
            if d.get("module"):
                html += f"<b>ğŸ“¦ Module:</b> {d['module']}<br>"
            if d.get("affected_function"):
                html += f"<b>âš™ï¸ Affected Function:</b> {d['affected_function']}<br>"
            if d.get("history"):
                html += f"<br><b>ğŸ“œ History:</b><br><div style='margin-left:10px;color:#555;'>{d['history']}</div><br>"
            if d.get("benefits"):
                html += f"<b>âœ… Benefits:</b><br><div style='margin-left:10px;color:#555;'>{d['benefits']}</div><br>"
            if d.get("description"):
                html += f"<b>ğŸ“ Description:</b><br><div style='margin-left:10px;color:#555;'>{d['description']}</div>"
            
            # Problem Report ì„¹ì…˜ í•„ë“œ
            if d.get("issue_description"):
                html += f"<br><br><b>ğŸ”´ Issue Description:</b><br><div style='margin-left:10px;color:#c00;'>{d['issue_description']}</div>"
            if d.get("root_cause"):
                html += f"<br><b>ğŸ” Root Cause:</b><br><div style='margin-left:10px;color:#555;'>{d['root_cause']}</div>"
            if d.get("solution"):
                html += f"<br><b>ğŸ’¡ Solution:</b><br><div style='margin-left:10px;color:#060;'>{d['solution']}</div>"
            
            if d.get("cv_changes"):
                # CV Changes í…Œì´ë¸”
                html += f"<br><br><b>ğŸ”„ CV (Configurable Variable) Changes:</b><br>{d['cv_changes']}"
            if d.get("factory_automation_changes"):
                # Factory Automation Changes í…Œì´ë¸”
                html += f"<br><br><b>ğŸ­ Factory Automation Changes:</b><br>{d['factory_automation_changes']}"
            if d.get("recipe_parameter_changes"):
                # Recipe Parameter Changes í…Œì´ë¸”
                html += f"<br><br><b>ğŸ“‹ Recipe Parameter Changes:</b><br>{d['recipe_parameter_changes']}"
            if d.get("ui_changes"):
                # UI Changes í…Œì´ë¸”
                html += f"<br><br><b>ğŸ–¥ï¸ UI Changes:</b><br>{d['ui_changes']}"
            if d.get("alarm_changes"):
                # Alarm Changes í…Œì´ë¸”
                html += f"<br><br><b>ğŸš¨ Alarm Changes:</b><br>{d['alarm_changes']}"
        
        # ë‹¤ë¥¸ ë²„ì „ì—ì„œë„ ë°œê²¬ëœ ê²½ìš°
        all_results = self.search_pr(pr_number)
        if len(all_results) > 1:
            versions = [r['sw_version'].replace('_ReleaseNotes', '') for r in all_results[:5]]
            html += f"<br><br>ğŸ’¡ ì´ PRì€ <b>{len(all_results)}ê°œ ë²„ì „</b>ì—ì„œ ë°œê²¬ë¨: {', '.join(versions)}"
            if len(all_results) > 5:
                html += f" ì™¸ {len(all_results) - 5}ê°œ"
        
        return html


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_indexer_instance = None

def get_swrn_indexer() -> SWRNIndexer:
    """SWRN Indexer ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤"""
    global _indexer_instance
    if _indexer_instance is None:
        _indexer_instance = SWRNIndexer()
    return _indexer_instance


# CLI
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="SWRN PDF Indexer")
    parser.add_argument("--build", action="store_true", help="Build full index")
    parser.add_argument("--rebuild", action="store_true", help="Force rebuild index")
    parser.add_argument("--update", action="store_true", help="Update index (new files only)")
    parser.add_argument("--search", type=str, help="Search for PR number")
    parser.add_argument("--text", type=str, help="Full-text search")
    parser.add_argument("--stats", action="store_true", help="Show index statistics")
    parser.add_argument("--folder", type=str, help="SWRN folder path")
    
    args = parser.parse_args()
    
    indexer = SWRNIndexer(swrn_folder=args.folder) if args.folder else get_swrn_indexer()
    
    if args.build or args.rebuild:
        indexer.build_index(force_rebuild=args.rebuild)
    
    elif args.update:
        indexer.build_index(force_rebuild=False)
    
    elif args.search:
        print(f"\nğŸ” Searching for: {args.search}")
        print("-" * 40)
        result = indexer.format_pr_result(args.search)
        # HTML íƒœê·¸ ì œê±°í•˜ì—¬ ì½˜ì†” ì¶œë ¥
        import html
        clean = re.sub(r'<[^>]+>', '', result)
        clean = html.unescape(clean)
        print(clean)
    
    elif args.text:
        print(f"\nğŸ” Full-text search: {args.text}")
        print("-" * 40)
        results = indexer.search_text(args.text)
        for r in results:
            print(f"ğŸ“„ {r['filename']} (p.{r['page']})")
            print(f"   {r['snippet']}\n")
    
    elif args.stats:
        stats = indexer.get_stats()
        print("\nğŸ“Š Index Statistics")
        print("-" * 40)
        if stats["indexed"]:
            print(f"ğŸ“ Files: {stats['file_count']}")
            print(f"ğŸ“‘ Pages: {stats['total_pages']:,}")
            print(f"ğŸ”¢ PR entries: {stats['pr_entries']:,}")
            print(f"ğŸ†” Unique PRs: {stats['unique_prs']:,}")
            print(f"ğŸ’¾ DB size: {stats['db_size_mb']:.1f} MB")
        else:
            print("âŒ Index not built yet. Run with --build first.")
    
    else:
        parser.print_help()
